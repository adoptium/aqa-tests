#!groovy
import org.tap4j.consumer.TapConsumer;
import org.tap4j.consumer.TapConsumerFactory;
import org.tap4j.model.TestSet;

def makeTest(testParam) {
	String tearDownCmd = "$RESOLVED_MAKE; \$MAKE -f ./aqa-tests/TKG/testEnv.mk testEnvTeardown"
	String makeTestCmd = "$RESOLVED_MAKE; cd ./aqa-tests/TKG; \$MAKE $testParam"
	//unset LD_LIBRARY_PATH workaround for issue https://github.com/adoptium/infrastructure/issues/2934
	if (JDK_IMPL == 'hotspot' && JDK_VERSION == '8' && PLATFORM.contains('alpine-linux')) {
		makeTestCmd = "unset LD_LIBRARY_PATH; $makeTestCmd"
	}
	try {
		sh "$tearDownCmd"
		if (env.DOCKER_REGISTRY_URL && env.DOCKER_REGISTRY_URL_CREDENTIAL_ID) {
			withCredentials([usernamePassword(credentialsId: "${env.DOCKER_REGISTRY_URL_CREDENTIAL_ID}", usernameVariable: 'DOCKER_REGISTRY_CREDENTIALS_USR', passwordVariable: 'DOCKER_REGISTRY_CREDENTIALS_PSW')]) {
				sh "$makeTestCmd"
			}
		} else {
			sh "$makeTestCmd"
		}
	} catch (err) {
		currentBuild.result = 'UNSTABLE'
	} finally {
		sh "$tearDownCmd"
	}
}

def setupEnv() {
	env.JOBSTARTTIME = sh(script: 'LC_TIME=C date +"%a, %d %b %Y %T %z"', returnStdout: true).trim()

	// Terminate any previous test related processes that are running
        terminateTestProcesses()

	if ( params.JDK_VERSION ) {
		env.ORIGIN_JDK_VERSION = params.JDK_VERSION
		env.JDK_VERSION = params.JDK_VERSION.equalsIgnoreCase("next") ? "" : params.JDK_VERSION
	}
	env.USE_TESTENV_PROPERTIES = params.USE_TESTENV_PROPERTIES

	env.SPEC = "${SPEC}"
	if(!params.USE_TESTENV_PROPERTIES){
		ADOPTOPENJDK_REPO = params.ADOPTOPENJDK_REPO ? params.ADOPTOPENJDK_REPO : "https://github.com/adoptium/aqa-tests.git"
		OPENJ9_REPO = params.OPENJ9_REPO ? params.OPENJ9_REPO : "https://github.com/eclipse-openj9/openj9.git"
		String[] tkg = getGitRepoBranch(params.TKG_OWNER_BRANCH, "adoptium:master", "TKG")
		TKG_REPO = tkg[0]
		TKG_BRANCH = tkg[1]
		//For Zos, the right repo should be something like: git@github.ibm.com:runtimes/openj9-openjdk-jdk**-zos.git and for now there is only jdk11
		env.JDK_REPO = params.JDK_REPO ? params.JDK_REPO : ""
		if (env.SPEC.startsWith('zos')) {
			ADOPTOPENJDK_REPO = ADOPTOPENJDK_REPO.replace("https://github.com/","git@github.com:")
			OPENJ9_REPO = OPENJ9_REPO.replace("https://github.com/","git@github.com:")
		}
		OPENJ9_BRANCH = params.OPENJ9_BRANCH ? params.OPENJ9_BRANCH : "master"
	}

	PLATFORM = params.PLATFORM ? params.PLATFORM : ""
	ADOPTOPENJDK_BRANCH = params.ADOPTOPENJDK_BRANCH ? params.ADOPTOPENJDK_BRANCH : "master"
	CLONE_OPENJ9 = params.CLONE_OPENJ9 ? params.CLONE_OPENJ9 : "true"
	CUSTOM_TARGET = params.CUSTOM_TARGET ? params.CUSTOM_TARGET : ""
	UPSTREAM_JOB_NAME = params.UPSTREAM_JOB_NAME ? params.UPSTREAM_JOB_NAME : ""
	UPSTREAM_JOB_NUMBER = params.UPSTREAM_JOB_NUMBER ? params.UPSTREAM_JOB_NUMBER : ""
	SSH_AGENT_CREDENTIAL = params.SSH_AGENT_CREDENTIAL ? params.SSH_AGENT_CREDENTIAL : ""
	KEEP_WORKSPACE = params.KEEP_WORKSPACE ? params.KEEP_WORKSPACE : false
	OPENJ9_SHA = params.OPENJ9_SHA ? params.OPENJ9_SHA : ""
	CLOUD_PROVIDER = params.CLOUD_PROVIDER ? params.CLOUD_PROVIDER : ""
	env.JDK_BRANCH = params.JDK_BRANCH ? params.JDK_BRANCH : ""
	env.USER_CREDENTIALS_ID = params.USER_CREDENTIALS_ID ? params.USER_CREDENTIALS_ID : ""
	env.TEST_JDK_HOME = "$WORKSPACE/openjdkbinary/j2sdk-image"
	env.JVM_VERSION = params.JVM_VERSION ? params.JVM_VERSION : ""
	env.JVM_OPTIONS = params.JVM_OPTIONS ? params.JVM_OPTIONS : ""
        env.APPLICATION_OPTIONS = params.APPLICATION_OPTIONS ? params.APPLICATION_OPTIONS : ""
	env.EXTRA_DOCKER_ARGS = params.EXTRA_DOCKER_ARGS ? params.EXTRA_DOCKER_ARGS : ""
	env.OPENJDK_SHA = params.OPENJDK_SHA ? params.OPENJDK_SHA : ""
	env.OPENLIBERTY_SHA = params.OPENLIBERTY_SHA ? params.OPENLIBERTY_SHA : ""
	env.TEST_FLAG = params.TEST_FLAG ? params.TEST_FLAG : ''
	env.KEEP_REPORTDIR = params.KEEP_REPORTDIR ? params.KEEP_REPORTDIR : false
	SDK_RESOURCE = params.SDK_RESOURCE ? params.SDK_RESOURCE : "upstream"
	env.AUTO_DETECT = params.AUTO_DETECT
	env.EXTERNAL_CUSTOM_REPO=params.EXTERNAL_CUSTOM_REPO? params.EXTERNAL_CUSTOM_REPO : ""
	env.EXTERNAL_REPO_BRANCH=params.EXTERNAL_REPO_BRANCH ? params.EXTERNAL_REPO_BRANCH : "master"
	env.EXTERNAL_TEST_CMD=params.EXTERNAL_TEST_CMD ? params.EXTERNAL_TEST_CMD : "mvn clean install"
	env.DYNAMIC_COMPILE=params.DYNAMIC_COMPILE ? params.DYNAMIC_COMPILE : false
	env.USE_JRE=params.USE_JRE ? params.USE_JRE : false
	env.RERUN_LINK = ""
	env.FAILED_TESTS = ""
	env.FAILED_TEST_TARGET = ""
	env.CUSTOM_TARGET_KEY_VALUE =""
	env.DOCKER_REGISTRY_URL = params.DOCKER_REGISTRY_URL ? params.DOCKER_REGISTRY_URL : ""
	env.DOCKER_REGISTRY_DIR = params.DOCKER_REGISTRY_DIR ? params.DOCKER_REGISTRY_DIR : ""
	env.DOCKER_REGISTRY_URL_CREDENTIAL_ID = params.DOCKER_REGISTRY_URL_CREDENTIAL_ID ? params.DOCKER_REGISTRY_URL_CREDENTIAL_ID : ""
	ITERATIONS = params.ITERATIONS ? "${params.ITERATIONS}".toInteger() : 1
	env.TKG_ITERATIONS = params.TKG_ITERATIONS ? "${params.TKG_ITERATIONS}".toInteger() : 1
	env.EXIT_FAILURE = params.EXIT_FAILURE ? params.EXIT_FAILURE : false
	env.EXIT_SUCCESS = params.EXIT_SUCCESS ? params.EXIT_SUCCESS : false
	NUM_MACHINES = params.NUM_MACHINES ? params.NUM_MACHINES.toInteger() : 1

	if (JOB_NAME.contains("Grinder")) {
		def currentDate = new Date()
		def currentDateTime = currentDate.format("yyyyMMddHHmmss", TimeZone.getTimeZone('UTC'))
		env.TAP_NAME = "${JOB_NAME}_${currentDateTime}.tap"
	} else {
		env.TAP_NAME = "${JOB_NAME}.tap"
	}

	if (params.CODE_COVERAGE) {
		// GCOV strips # num from folder path in BUILD pipeline, e.g., /home/jenkins/workspace/Build_JDK11_x86-64_linux_Personal/build/linux-x86_64-normal-server-release/vm
		env.GCOV_PREFIX_STRIP = 1
		env.GCOV_PREFIX = env.TEST_JDK_HOME
	}

	if (params.JRE_IMAGE) {
		env.JRE_IMAGE = "${WORKSPACE}/${params.JRE_IMAGE}"
	}

	if (params.USE_JRE) {
		env.USE_JRE = 1
	}

	if (params.JDK_IMPL) {
		env.JDK_IMPL = params.JDK_IMPL
	} else if (params.JVM_VERSION) {
		env.JDK_IMPL = getJDKImpl(params.JVM_VERSION)
	}

	if( params.PERF_ROOT ) {
		env.PERF_ROOT = params.PERF_ROOT
	} else {
		env.PERF_ROOT = "$WORKSPACE/../../benchmarks"
	}

	env.JCK_VERSION = params.JCK_VERSION ? params.JCK_VERSION : ""
	env.JCK_ROOT = params.JCK_ROOT ? params.JCK_ROOT : ""
	env.JCK_GIT_REPO = params.JCK_GIT_REPO ? params.JCK_GIT_REPO : ""

	env.OCP_SERVER = params.OCP_SERVER ? params.OCP_SERVER : ''
	env.OCP_TOKEN = params.OCP_TOKEN ? params.OCP_TOKEN : ''

	if (env.BUILD_LIST.contains('external')) {
		env.DIAGNOSTICLEVEL ='noDetails'
	}

	if( params.DOCKERIMAGE_TAG ) {
		env.DOCKERIMAGE_TAG = params.DOCKERIMAGE_TAG
	}
	if ( env.SPEC.contains('sunos')) {
		sh 'env'
	} else {
		sh 'printenv'
	}
}

def setupParallelEnv() {
	stage('setupParallelEnv') {
		def maxChildJobNum = 25
		int childJobNum = 1
		def UPSTREAM_TEST_JOB_NAME = ""
		def UPSTREAM_TEST_JOB_NUMBER = ""

		if (params.PARALLEL == "NodesByIterations") {
			childJobNum = NUM_MACHINES
			// limit childJobNum
			if (childJobNum > 20) {
				echo "Due to the limited machines, NUM_MACHINES can only be set up to 20. Current NUM_MACHINES is ${NUM_MACHINES}."
				echo "Reset NUM_MACHINES to 20..."
				childJobNum = 20
			}
		} else if (params.PARALLEL == "Dynamic") {
			try {
				//get cached TRSS JSON data
				timeout(time: 1, unit: 'HOURS') {
					copyArtifacts fingerprintArtifacts: true, projectName: "getTRSSOutput", selector: lastSuccessful(), target: 'aqa-tests/TKG/resources/TRSS'
					sh "cd ./aqa-tests/TKG/resources/TRSS; gzip -cd TRSSOutput.tar.gz | tar xof -; rm TRSSOutput.tar.gz"
				}
			} catch (Exception e) {
				echo 'Exception: ' + e.toString()
				echo 'Cannot get cached TRSS JSON data. Skipping copyArtifacts...'
			}

			try {
				//get pre-staged jars from test.getDependency build
				timeout(time: 2, unit: 'HOURS') {
					copyArtifacts fingerprintArtifacts: true, projectName: "test.getDependency", selector: lastSuccessful(), target: 'aqa-tests/TKG/lib'
				}
			} catch (Exception e) {
				echo 'Exception: ' + e.toString()
				echo 'Cannot run copyArtifacts from test.getDependency. Skipping copyArtifacts...'
			}

			String PARALLEL_OPTIONS = "TEST=${TARGET}"
			if (params.TRSS_URL) {
				PARALLEL_OPTIONS += " TRSS_URL=${params.TRSS_URL}"
			}
			int NUM_LIST = -1
			int MAX_NUM_MACHINES = Math.min(20, getMachineLimit());
			if (params.NUM_MACHINES) {
				int numOfMachines = getNumMachines()
				PARALLEL_OPTIONS += " NUM_MACHINES=${numOfMachines} TEST_TIME="
				NUM_LIST = genParallelList(PARALLEL_OPTIONS)
			} else if (params.TEST_TIME) {
				String PARALLEL_OPTIONS_TEMP = PARALLEL_OPTIONS
				PARALLEL_OPTIONS += " TEST_TIME=${params.TEST_TIME} NUM_MACHINES="
				NUM_LIST = genParallelList(PARALLEL_OPTIONS)
				if (NUM_LIST > MAX_NUM_MACHINES) {
					echo "TEST_TIME (${params.TEST_TIME} minutes) is not possible as it exceeds the machine limit."
					echo "Regenerate parallel list with NUM_MACHINES=${MAX_NUM_MACHINES}."
					PARALLEL_OPTIONS = PARALLEL_OPTIONS_TEMP + " NUM_MACHINES=${MAX_NUM_MACHINES} TEST_TIME="
					NUM_LIST = genParallelList(PARALLEL_OPTIONS)
				}
			} else {
				PARALLEL_OPTIONS += " TEST_TIME= NUM_MACHINES="
				NUM_LIST = genParallelList(PARALLEL_OPTIONS)
			}

			if (NUM_LIST > 0) {
				childJobNum = NUM_LIST
				echo "Saving parallelList.mk file on jenkins..."
				dir('aqa-tests/TKG') {
					archiveArtifacts artifacts: 'parallelList.mk', fingerprint: true, allowEmptyArchive: false
				}
			} else {
				assert false : "Build failed because cannot find NUM_LIST in parallelList.mk file."
			}
		}

		UPSTREAM_TEST_JOB_NAME = JOB_NAME
		UPSTREAM_TEST_JOB_NUMBER = BUILD_NUMBER
		echo "[PARALLEL: ${params.PARALLEL}] childJobNum is ${childJobNum}, creating jobs and running them in parallel..."
		parallel_tests = [:]
		create_jobs = [:]

		for (int i = 0; i < childJobNum; i++) {
			def buildListName = env.BUILD_LIST
			def childTest = ""
			def childTarget = TARGET
			if (params.PARALLEL == "NodesByIterations") {
				childTest = "iteration_${i}"
			} else if (params.PARALLEL == "Dynamic") {
				childTest = "testList_${i}"
				childTarget = "-f parallelList.mk ${childTest}"
			}
			def TEST_JOB_NAME = "${JOB_NAME}_${childTest}"

			generateJob(create_jobs, childTest, TEST_JOB_NAME)

			def childParams = []
			// loop through all the params and change the parameters if needed
			params.each { param ->
				// set PARALLEL, NUM_MACHINES and TEST_TIME to default values
				if (param.key == "BUILD_LIST") {
					childParams << string(name: param.key, value: "${buildListName}")
				} else if (param.key == "TARGET") {
					childParams << string(name: param.key, value: "${childTarget}")
				} else if (param.key == "PARALLEL") {
					childParams << string(name: param.key, value: "None")
				} else if (param.key == "NUM_MACHINES") {
					childParams << string(name: param.key, value: "")
				} else if (param.key == "TEST_TIME") {
					childParams << string(name: param.key, value: "")
				}else {
					def value = param.value.toString()
					if (value == "true" || value == "false") {
						childParams << booleanParam(name: param.key, value: value.toBoolean())
					} else {
						childParams << string(name: param.key, value: value)
					}
				}
			}

			childParams << string(name: 'UPSTREAM_TEST_JOB_NAME', value: UPSTREAM_TEST_JOB_NAME)
			childParams << string(name: 'UPSTREAM_TEST_JOB_NUMBER', value: UPSTREAM_TEST_JOB_NUMBER)

			parallel_tests[childTest] = {
				build job: TEST_JOB_NAME, parameters: childParams, propagate: false
			}
		}

		if (create_jobs) {
			parallel create_jobs
		}

		// return to top level pipeline file in order to exit node block before running tests in parallel
	}

}

// Returns NUM_LIST from parallelList.mk. 
// NUM_LIST can be different than numOfMachines.
def genParallelList(PARALLEL_OPTIONS) {
	String unsetLLP = ""
	//unset LD_LIBRARY_PATH workaround for issue https://github.com/adoptium/infrastructure/issues/2934
	if (JDK_IMPL == 'hotspot' && JDK_VERSION == '8' && PLATFORM.contains('alpine-linux')) {
		unsetLLP = "unset LD_LIBRARY_PATH;"
	}
	sh "cd ./aqa-tests/TKG; ${unsetLLP} make genParallelList ${PARALLEL_OPTIONS}"
	def parallelList = "aqa-tests/TKG/parallelList.mk"
	int NUM_LIST = -1
	if (fileExists("${parallelList}")) {
		if (SPEC.startsWith('zos')) {
			echo 'Converting parallelList.mk file from ebcdic to ascii...'
			sh "iconv -f ibm-1047 -t iso8859-1 ${parallelList} > ${parallelList}.ascii; rm ${parallelList}; mv ${parallelList}.ascii ${parallelList}"
		}
		echo "read parallelList.mk file: ${parallelList}"
		def properties = readProperties file: "${parallelList}"
		if (properties.NUM_LIST) {
			NUM_LIST = properties.NUM_LIST.toInteger()
		}
	}
	return NUM_LIST
}

// Returns num
// num = params.NUM_MACHINES. If it is not provided, the default value is 1
// num cannot be greater than machines limit
def getNumMachines() {
	int num = params.NUM_MACHINES ? params.NUM_MACHINES.toInteger() : 1
	int limit = getMachineLimit()
	echo "machine limit is ${limit}"
	if (num > limit) {
		echo "Number of machines cannot be greater than ${limit}. Set num to ${limit}"
		num = limit
	}
	return num
}

def getMachineLimit(){
	int limit = nodesByLabel(LABEL).size()
	// Set limit for dynamic vm agents to 100
	if (LABEL.contains('ci.agent.dynamic')) {
		limit = 100
	}
	return limit
}

def createJob( TEST_JOB_NAME, ARCH_OS ) {

	def jobParams = [:]
	jobParams.put('TEST_JOB_NAME', TEST_JOB_NAME)
	jobParams.put('ARCH_OS_LIST', ARCH_OS)

	if (params.DAYS_TO_KEEP) {
		jobParams.put('DAYS_TO_KEEP', DAYS_TO_KEEP)
	}

	if (params.BUILDS_TO_KEEP) {
		jobParams.put('BUILDS_TO_KEEP', BUILDS_TO_KEEP)
	}

	//get level and group if TEST_JOB_NAME matches the format of Test_openjdk11_j9_extended.functional_ppc64_aix
	//otherwise, use default level and group value in template
	if (TEST_JOB_NAME.startsWith("Test_openjdk")) {
		def level = ""
		def group = ""
		def tokens = TEST_JOB_NAME.split('_');
		if (tokens.size() > 3 && tokens[3].contains(".")) {
			level = tokens[3].split("\\.")[0]
			group = tokens[3].split("\\.")[1]
		}

		if (level && group) {
			jobParams.put('LEVELS', level)
			jobParams.put('GROUPS', group)
		}
	}

	def templatePath = 'aqa-tests/buildenv/jenkins/testJobTemplate'
	if (!fileExists(templatePath)) {
		sh "curl -Os https://raw.githubusercontent.com/adoptium/aqa-tests/master/buildenv/jenkins/testJobTemplate"
		templatePath = 'testJobTemplate'
	}

	if (params.LIGHT_WEIGHT_CHECKOUT) {
		jobParams.put('LIGHT_WEIGHT_CHECKOUT', params.LIGHT_WEIGHT_CHECKOUT)
	}

	def create = jobDsl targets: templatePath, ignoreExisting: false, additionalParameters: jobParams
	return create
}

def setup() {
	stage('Setup') {
		setupEnv()

		if (params.SDK_RESOURCE == 'nightly' && params.CUSTOMIZED_SDK_URL) {
			// remove single quote to allow variables to be set in CUSTOMIZED_SDK_URL
			CUSTOMIZED_SDK_URL_OPTION = "-c ${params.CUSTOMIZED_SDK_URL}"
		} else if (params.CUSTOMIZED_SDK_URL) {
			SDK_RESOURCE = "customized"
			CUSTOMIZED_SDK_URL_OPTION = "-c '${params.CUSTOMIZED_SDK_URL}'"
			if (params.ADDITIONAL_ARTIFACTS_REQUIRED == "RI_JDK") {
				def server = Artifactory.server params.ARTIFACTORY_SERVER
				def artifactoryUrl = server.getUrl()
				def repoForRi = ''
				def riURL = ''
				if (params.ARTIFACTORY_REPO.contains(',')) {
					String[] repos = params.ARTIFACTORY_REPO.split(",")
					// Assumption: ARTIFACTORY_REPO=X,Y (X=to upload results, Y=to download ri)
					repoForRi = repos[1].trim()
					if (!env.SPEC.startsWith('aix') && !env.SPEC.startsWith('zos')) {
						riURL = "${artifactoryUrl}/${repoForRi}/Latest/${PLATFORM}/${JDK_VERSION}"
					}
				}
				CUSTOMIZED_SDK_URL_OPTION = "-c '${params.CUSTOMIZED_SDK_URL} ${riURL}'"
			}
		} else {
			CUSTOMIZED_SDK_URL_OPTION = ""
		}

		if (SDK_RESOURCE == 'upstream' && !params.CUSTOMIZED_SDK_URL) {
			timeout(time: 1, unit: 'HOURS') {
				dir('openjdkbinary') {
					step([$class: 'CopyArtifact',
							fingerprintArtifacts: true,
							flatten: true,
							filter: "**/*.tar.gz,**/*.tgz,**/*.zip,**/*.jar,**/*.Z",
							projectName: "${params.UPSTREAM_JOB_NAME}",
							selector: [$class: 'SpecificBuildSelector', buildNumber: "${params.UPSTREAM_JOB_NUMBER}"]])
				}
			}
		}
		OPENJ9_REPO_OPTION = ""
		OPENJ9_BRANCH_OPTION = ""
		TKG_REPO_OPTION = ""
		TKG_BRANCH_OPTION = ""
		if(!params.USE_TESTENV_PROPERTIES){
			OPENJ9_REPO_OPTION = "--openj9_repo ${OPENJ9_REPO}"
			OPENJ9_BRANCH_OPTION = "--openj9_branch ${OPENJ9_BRANCH}"
			TKG_REPO_OPTION = "--tkg_repo ${TKG_REPO}"
			TKG_BRANCH_OPTION = "--tkg_branch ${TKG_BRANCH}"
		}
		CLONE_OPENJ9_OPTION = (params.CLONE_OPENJ9) ? "--clone_openj9 ${params.CLONE_OPENJ9}" : ""
		OPENJ9_SHA_OPTION = (params.OPENJ9_SHA) ? "--openj9_sha ${params.OPENJ9_SHA}" : ""
		JDK_VERSION_OPTION = env.JDK_VERSION ? "-j ${env.JDK_VERSION}" : ""
		JDK_IMPL_OPTION = env.JDK_IMPL ? "-i ${env.JDK_IMPL}" : ""

		// system test repository exports to be used by system/common.xml
		if(!params.USE_TESTENV_PROPERTIES){
			String[] adoptSystemTest = getGitRepoBranch(params.ADOPTOPENJDK_SYSTEMTEST_OWNER_BRANCH, "adoptium:master", "aqa-systemtest")
			env.ADOPTOPENJDK_SYSTEMTEST_REPO = adoptSystemTest[0]
			env.ADOPTOPENJDK_SYSTEMTEST_BRANCH = adoptSystemTest[1]

			String[] openj9SystemTest = getGitRepoBranch(params.OPENJ9_SYSTEMTEST_OWNER_BRANCH, "eclipse:master", "openj9-systemtest")
			env.OPENJ9_SYSTEMTEST_REPO = openj9SystemTest[0]
			env.OPENJ9_SYSTEMTEST_BRANCH = openj9SystemTest[1]

			String[] stf = getGitRepoBranch(params.STF_OWNER_BRANCH, "adoptium:master", "STF")
			env.STF_REPO = stf[0]
			env.STF_BRANCH = stf[1]
		}
		// vendor test
		// expect VENDOR_TEST_* to be comma separated string parameters
		VENDOR_TEST_REPOS = (params.VENDOR_TEST_REPOS) ? "--vendor_repos \"${params.VENDOR_TEST_REPOS}\"" : ""
		VENDOR_TEST_BRANCHES = (params.VENDOR_TEST_BRANCHES) ? "--vendor_branches \"${params.VENDOR_TEST_BRANCHES}\"" : ""
		VENDOR_TEST_DIRS = (params.VENDOR_TEST_DIRS) ? "--vendor_dirs \"${params.VENDOR_TEST_DIRS}\"" : ""
		VENDOR_TEST_SHAS = (params.VENDOR_TEST_SHAS) ? "--vendor_shas \"${params.VENDOR_TEST_SHAS}\"" : ""

		// handle three cases (true/false/null) in params.TEST_IMAGES_REQUIRED and params.DEBUG_IMAGES_REQUIRED
		// Only set image required to false if params is set to false. In get.sh, the default value is true
		TEST_IMAGES_REQUIRED = (params.TEST_IMAGES_REQUIRED == false) ? "--test_images_required false" : ""
		DEBUG_IMAGES_REQUIRED = (params.DEBUG_IMAGES_REQUIRED == false) ? "--debug_images_required false" : ""
		CODE_COVERAGE_OPTION = params.CODE_COVERAGE ? "--code_coverage true" : ""
		ADDITIONAL_ARTIFACTS_REQUIRED_OPTION = (params.ADDITIONAL_ARTIFACTS_REQUIRED) ? "--additional_artifacts_required ${params.ADDITIONAL_ARTIFACTS_REQUIRED}" : ""

		CURL_OPTS = (params.CURL_OPTS) ? "--curl_opts \"${params.CURL_OPTS}\"" : ""
		GET_SH_CMD = "./get.sh -s `pwd`/.. -p $PLATFORM -r ${SDK_RESOURCE} ${JDK_VERSION_OPTION} ${JDK_IMPL_OPTION} ${CUSTOMIZED_SDK_URL_OPTION} ${CLONE_OPENJ9_OPTION} ${OPENJ9_REPO_OPTION} ${OPENJ9_BRANCH_OPTION} ${OPENJ9_SHA_OPTION} ${TKG_REPO_OPTION} ${TKG_BRANCH_OPTION} ${VENDOR_TEST_REPOS} ${VENDOR_TEST_BRANCHES} ${VENDOR_TEST_DIRS} ${VENDOR_TEST_SHAS} ${TEST_IMAGES_REQUIRED} ${DEBUG_IMAGES_REQUIRED} ${CODE_COVERAGE_OPTION} ${CURL_OPTS} ${ADDITIONAL_ARTIFACTS_REQUIRED_OPTION}"
		RESOLVED_MAKE = "if [ `uname` = AIX ] || [ `uname` = SunOS ] || [ `uname` = *BSD ]; then MAKE=gmake; else MAKE=make; fi"
		dir( WORKSPACE) {
			// use sshagent with Jenkins credentials ID for all platforms except zOS
			// on zOS use the user's ssh key
			if (!env.SPEC.startsWith('zos')) {
				get_sources_with_authentication()
			} else {
				get_sources()
			}
			getJobProperties()
		}
	}
}

def setup_jck_interactives() {
	def targetDir = "${env.WORKSPACE}/../../jck_run/jdk${JDK_VERSION}/jdk"
	if (PLATFORM.contains("windows")) {
		targetDir = "c:/Users/jenkins/jck_run/jdk${JDK_VERSION}/jdk"
	}
	def tarBall = CUSTOMIZED_SDK_URL.tokenize('/').last()
	echo "tarBall is ${tarBall}"
	def jckRunDirExists = sh(script: """
		if [ -d "${targetDir}" ]; then
			echo true
		else
			echo false
		fi
		""", returnStdout: true).toBoolean()

	if (jckRunDirExists) {
		def jdkDir = ""
		if (PLATFORM.contains("windows")) {
			jdkDir = sh(script: "unzip -l `pwd`/openjdkbinary/${tarBall} | head -n 4 | tail -n 1 | xargs -n 1 echo | tail -n 1", returnStdout: true).trim().replaceFirst(".\$","")
			if (PLATFORM.contains("x86-32_windows")) {
				jdkDir = "${jdkDir}_32"
			} else if (PLATFORM.contains("x86-64_windows")) {
				jdkDir = "${jdkDir}_64"
			}
		} else {
			jdkDir =  sh(script: "tar -tf `pwd`/openjdkbinary/${tarBall} | head -1", returnStdout: true).trim().replaceFirst(".\$","")
		}
		def jckRunDir = "${targetDir}/${jdkDir}"
		def jckRunJDKExists = sh(script: """
		if [ -d "${jckRunDir}" ]; then
			echo true
		else
			echo false
		fi
		""", returnStdout: true).toBoolean()

		if (!jckRunJDKExists) {
			sh returnStatus: true, script: """
				cd ${targetDir}
				mkdir ${jdkDir}
				cd ${jdkDir}
				cp -r ${TEST_JDK_HOME}/* .
				chgrp -R jck ${targetDir}/${jdkDir}
				chmod -R 775 ${targetDir}/${jdkDir}
				"""
		}
	}
}

def getJobProperties() {
	def jobProperties = "./aqa-tests/job.properties"
	if (fileExists("${jobProperties}")) {
		echo "readProperties file: ${jobProperties}"
		def properties = readProperties file: "${jobProperties}"
		if (properties.TEST_JDK_HOME) {
			env.TEST_JDK_HOME = properties.TEST_JDK_HOME
			echo "Reset TEST_JDK_HOME to ${TEST_JDK_HOME}"
		}
	}
}

def get_sources_with_authentication() {
	sshagent(credentials:["${params.USER_CREDENTIALS_ID}"], ignoreMissing: true) {
		get_sources()
	}
}

def get_sources() {
	dir('aqa-tests') {
		if (params.CUSTOMIZED_SDK_URL_CREDENTIAL_ID) {
			// USERNAME and PASSWORD reference with a withCredentials block will not be visible within job output
			withCredentials([usernamePassword(credentialsId: "${params.CUSTOMIZED_SDK_URL_CREDENTIAL_ID}", usernameVariable: 'USERNAME', passwordVariable: 'PASSWORD')]) {
				sh "$GET_SH_CMD"
			}
		} else {
			sh "$GET_SH_CMD"
		}
	}
	if (params.SETUP_JCK_RUN && env.BUILD_LIST.contains('jck') && SDK_RESOURCE.contains('customized')) {
		setup_jck_interactives()
	}
}
def makeCompileTest(){
	String makeTestCmd = "bash ./compile.sh ${USE_TESTENV_PROPERTIES}"
	//unset LD_LIBRARY_PATH workaround for issue https://github.com/adoptium/infrastructure/issues/2934
	if (JDK_IMPL == 'hotspot' && JDK_VERSION == '8' && PLATFORM.contains('alpine-linux')) {
		makeTestCmd = "unset LD_LIBRARY_PATH; $makeTestCmd"
	}
	dir('aqa-tests') {
		if (!env.SPEC.startsWith('zos')) {
			sshagent (credentials: ["$params.SSH_AGENT_CREDENTIAL"], ignoreMissing: true) {
				sh "$makeTestCmd";
			}
		} else {
			sh "$makeTestCmd";
		}
	}
}

def buildTest() {
	stage('Build') {
		echo 'Building tests...'

		if ( params.PERF_CREDENTIALS_ID ) {
			withCredentials([usernamePassword(credentialsId: "$params.PERF_CREDENTIALS_ID",
					passwordVariable: "PASSWORD_VAR", usernameVariable: "USERNAME_VAR")]) {
				env.PERF_USERNAME = USERNAME_VAR
				env.PERF_PASSWORD = PASSWORD_VAR
			}
		}

		if (params.UPSTREAM_TEST_JOB_NAME && params.UPSTREAM_TEST_JOB_NUMBER) {
			try {
				timeout(time: 1, unit: 'HOURS') {
					copyArtifacts fingerprintArtifacts: true, projectName: params.UPSTREAM_TEST_JOB_NAME, selector: specific(params.UPSTREAM_TEST_JOB_NUMBER), filter: "**/parallelList.mk", target: './aqa-tests/TKG/'
				}
			} catch (Exception e) {
				echo 'Exception: ' + e.toString()
				echo "Cannot run copyArtifacts from ${params.UPSTREAM_TEST_JOB_NAME} ${params.UPSTREAM_TEST_JOB_NUMBER}. Skipping copyArtifacts..."
			}
		}

		try {
			//get pre-staged jars from test.getDependency build before test compilation
			timeout(time: 2, unit: 'HOURS') {
				copyArtifacts fingerprintArtifacts: true, projectName: "test.getDependency", selector: lastSuccessful(), target: 'aqa-tests/TKG/lib'
			}
		} catch (Exception e) {
			echo 'Exception: ' + e.toString()
			echo 'Cannot run copyArtifacts from test.getDependency. Skipping copyArtifacts...'
		}

		try {
			if (env.BUILD_LIST.startsWith('system')) {
				//get pre-staged test jars from systemtest.getDependency build before system test compilation
				timeout(time: 2, unit: 'HOURS') {
					copyArtifacts fingerprintArtifacts: true, projectName: "systemtest.getDependency", selector: lastSuccessful(), target: 'aqa-tests'
				}
			}
		} catch (Exception e) {
			echo 'Exception: ' + e.toString()
			echo 'Cannot run copyArtifacts from systemtest.getDependency. Skipping copyArtifacts...'
		}

		if (BUILD_LIST.contains("external")){
			try {
				timeout(time: 2, unit: 'HOURS') {
					copyArtifacts fingerprintArtifacts: true, projectName: "UploadFileOnJenkins", selector: specific("2"), target: 'aqa-tests/external/criu/'
				}
			} catch (Exception e) {
				echo 'Exception: ' + e.toString()
				echo 'Cannot run copyArtifacts from UploadFileOnJenkins. Skipping copyArtifacts...'
			}
		}

		if (fileExists('openjdkbinary/openjdk-test-image')) {
			env.TESTIMAGE_PATH = "$WORKSPACE/openjdkbinary/openjdk-test-image"
		}

		if (fileExists('openjdkbinary/openjdk-test-image/openj9')) {
			env.NATIVE_TEST_LIBS = "$WORKSPACE/openjdkbinary/openjdk-test-image/openj9"
		}

		if (!params.DYNAMIC_COMPILE) {
			if(params.CUSTOMIZED_SDK_URL_CREDENTIAL_ID) {
				withCredentials([usernamePassword(credentialsId: "${params.CUSTOMIZED_SDK_URL_CREDENTIAL_ID}",
						usernameVariable: 'USERNAME', passwordVariable: 'PASSWORD')]) {
					makeCompileTest()
				}
			} else {
				makeCompileTest()
			}
		}

		if (params.CODE_COVERAGE) {
			echo "Clean gcda files before generating new Code Coverage info"
			sh "find ${WORKSPACE}/openjdkbinary/j2sdk-image -name '*.gcda' -type f -delete"
		}
	}
}

def runTest( ) {
	stage('Test') {
		echo 'Running tests...'
		def CUSTOM_OPTION = ''

		TARGET = "${params.TARGET}";
		if (TARGET.contains('custom') && CUSTOM_TARGET!='') {
			if (TARGET == 'system_custom') {
				env.SYSTEM_CUSTOM_TARGET=CUSTOM_TARGET
			} else {
				// remove suffix, then set CUSTOM_OPTION (i.e., jdk_custom_0 will become jdk_custom)
				def removeSuffix = TARGET.replaceAll(/_\d+$/, "")
				CUSTOM_OPTION = "${removeSuffix.toUpperCase()}_TARGET='${CUSTOM_TARGET}'"
			}
		}
		if (!TARGET.startsWith('-f')) {
			TARGET="_${params.TARGET}"
		} else if (TARGET.contains('-f parallelList.mk') && SPEC.startsWith('zos')) {
			def parallelList = "aqa-tests/TKG/parallelList.mk"
			if (fileExists("${parallelList}")) {
				echo 'Converting parallelList.mk file from ascii to ebcdic...'
				sh "iconv -f iso8859-1 -t ibm-1047 ${parallelList} > ${parallelList}.ebcdic; rm ${parallelList}; mv ${parallelList}.ebcdic ${parallelList}"
			}
		}

		RUNTEST_CMD = "${TARGET} ${CUSTOM_OPTION}"
		if (env.BUILD_LIST.contains('jck') || env.BUILD_LIST.contains('openjdk') || env.BUILD_LIST.contains('functional')) {
			if (env.SPEC.startsWith('aix')) {
				sh "/usr/bin/X11/X -force -vfb -x abx -x dbe -x GLX -secIP 000 :0 &"
				env.DISPLAY = "unix:0"
				echo "env.DISPLAY is ${env.DISPLAY}"

			} else if (env.SPEC.startsWith('sunos')) {
				sh "/usr/X11/bin/Xvfb :2 -screen 0 1024x768x24 &"
				env.DISPLAY = ":2"
				echo "env.DISPLAY is ${env.DISPLAY}"
			}
		}
		for (int i = 1; i <= ITERATIONS; i++) {
			echo "ITERATION: ${i}/${ITERATIONS}"
			if (env.SPEC.contains('linux') && !(LABEL.contains('ci.agent.dynamic') && CLOUD_PROVIDER == 'azure') && (BUILD_LIST != "external")) {
				// Add an additional 10 second timeout due to issue: https://github.com/adoptium/temurin-build/issues/2368#issuecomment-756683888
				wrap([$class: 'Xvfb', autoDisplayName: true, timeout:10]) {
					def DISPLAY = sh (
							script: 'ps -f  | grep \'[X]vfb\' | awk \'{print \$9}\'',
							returnStdout: true
					).trim()
					env.DISPLAY = "${DISPLAY}"
					echo "env.DISPLAY is ${env.DISPLAY}"
					makeTest("${RUNTEST_CMD}")
				}
			} else {
				makeTest("${RUNTEST_CMD}")
			}
		}

		if (params.CODE_COVERAGE) {
			echo 'Generating Code Coverage Reports...'
			dir("$WORKSPACE/openjdkbinary/j2sdk-image") {
				// Current lcov generates "Cannot open source file" info, but does not affect results, since Build and Test paths difference are corrected after summary.
				sh "lcov --capture --quiet --directory . --output-file codeCoverageInfoOrigin.info --rc geninfo_adjust_src_path='/home/jenkins/workspace/ => ${WORKSPACE}/openjdkbinary/j2sdk-image/jenkins/workspace/'"
				sh "lcov --quiet --output-file codeCoverageInfoFinal.info --remove codeCoverageInfoOrigin.info '/usr/include/*' '/usr/local/*' '/home/*/attrlookup.gperf'"
				sh "genhtml --quiet codeCoverageInfoFinal.info --output-directory code_coverage_report"
			}
		}

		def resultSum = [:]
		def matcher = manager.getLogMatcher(".*(TOTAL: \\d+)\\s*(EXECUTED: \\d+)\\s*(PASSED: \\d+)\\s*(FAILED: \\d+)\\s*(DISABLED: \\d+)?\\s*(SKIPPED: \\d+)\\s*\$")
		if (matcher?.matches()) {
			for (int i = 1; i <= matcher.groupCount(); i++) {
				if (matcher.group(i) != null) {
					def matchVals = matcher.group(i).split(": ")
					resultSum[matchVals[0]] = matchVals[1] as int
				}
			}
			checkTestResults(resultSum)
		} else {
			currentBuild.result = 'FAILURE'
			echo 'Could not find test result, set build result to FAILURE.'
			def summary = manager.createSummary("error.svg")
			summary.appendText("TEST BUILD FAILURE!", false)
		}
	}
}

def checkTestResults(results) {
	if (results.isEmpty()) {
		return
	}

	def summary = null

	if (results["TOTAL"] == 0) {
		currentBuild.result = 'FAILURE'
		echo 'No test ran, set build result to FAILURE.'
		summary = manager.createSummary("folder-delete.svg")
		summary.appendText("NO TEST FOUND!", false)
		return
	}

	if (results["FAILED"] != 0) {
		currentBuild.result = 'UNSTABLE'
		echo 'There were test failures, set build result to UNSTABLE.'
		summary = manager.createSummary("warning.svg")
	} else {
		summary = manager.createSummary("accept.svg")
	}

	summary.appendText("TEST TARGETS SUMMARY:<ul>", false)
	results.each {
		summary.appendText("<li><b>$it.key</b> : $it.value</li>", false)
	}
	summary.appendText("</ul>", false)
}

def post(output_name) {
	stage('Post') {
		if (env.DISPLAY != null) {
			env.DISPLAY = ""
		}
		if (output_name.contains(',')) {
			output_name = "specifiedTarget"
		}
		else {
			output_name = output_name.replace("/","_")
		}
		def tar_cmd = "tar -cf"
		// Use pigz if we can as it is faster - 2> hides fallback message
		def tar_cmd_suffix = "| (pigz -9 2>/dev/null || gzip -9)"
		def suffix = ".tar.gz"
		def pax_opt = ""
		if (SPEC.startsWith('zos')) {
			echo 'Converting tap file from ebcdic to ascii...'
			sh 'cd ./aqa-tests/TKG'
			def tapFiles = findFiles(glob: "**/*.tap")
			for (String tapFile : tapFiles) {
				sh "iconv -f ibm-1047 -t iso8859-1 ${tapFile} > ${tapFile}.ascii; rm ${tapFile}; mv ${tapFile}.ascii ${tapFile}"
			}

			tar_cmd = "pax -wf"
			suffix = ".pax.Z"
			pax_opt = "-x pax"
			tar_cmd_suffix = ""
		}

		step([$class: "TapPublisher", testResults: "aqa-tests/TKG/**/*.tap", outputTapToConsole: false, failIfNoResults: true])

		junit allowEmptyResults: true, keepLongStdio: true, testResults: '**/work/**/*.jtr.xml, **/result/**/*.jtr.xml, **/junitreports/**/*.xml, **/external_test_reports/**/*.xml'

		//call the archive function for each file
		archiveFile("aqa-tests/testenv/testenv.properties", true)
		archiveFile("aqa-tests/TKG/**/*.tap", true)
		archiveAQAvitFiles()

		if (env.BUILD_LIST.startsWith('jck')) {
			xunit (
					tools: [Custom(customXSL: "$WORKSPACE/aqa-tests/jck/xUnit.xsl",
							deleteOutputFiles: true,
							failIfNotNew: true,
							pattern: "**/TKG/output_*/**/report.xml",
							skipNoTestFiles: true,
							stopProcessingIfError: true)]
			)
		}

		//for performance test, archive regardless the build result
		if (env.BUILD_LIST.startsWith('perf')) {
			def benchmark_output_tar_name = "benchmark_test_output${suffix}"
			sh "${tar_cmd} ${benchmark_output_tar_name} ${pax_opt} ./aqa-tests/TKG/output_*"
			if (!params.ARTIFACTORY_SERVER) {
				echo "ARTIFACTORY_SERVER is not set. Saving artifacts on jenkins."
				archiveArtifacts artifacts: benchmark_output_tar_name, fingerprint: true, allowEmptyArchive: true
			} else {
				def pattern = "${env.WORKSPACE}/*_output.*"
				uploadToArtifactory(pattern)
			}
		} else if ((currentBuild.result == 'UNSTABLE' || currentBuild.result == 'FAILURE' || currentBuild.result == 'ABORTED') || params.ARCHIVE_TEST_RESULTS) {
			def test_output_tar_name = "${output_name}_test_output${suffix}"
			if (tar_cmd.startsWith('tar')) {
				sh "${tar_cmd} - ${pax_opt} ./aqa-tests/TKG/output_* ${tar_cmd_suffix} > ${test_output_tar_name}"
			} else {
				sh "${tar_cmd} ${test_output_tar_name} ${pax_opt} ./aqa-tests/TKG/output_* ${tar_cmd_suffix}"
			}

			// TODO: archiveFile() should be used
			if (!params.ARTIFACTORY_SERVER) {
				echo "ARTIFACTORY_SERVER is not set. Saving artifacts on jenkins."
				archiveArtifacts artifacts: test_output_tar_name, fingerprint: true, allowEmptyArchive: true
			} else {
				def pattern = "${env.WORKSPACE}/*_output.*"
				uploadToArtifactory(pattern)
			}

			if (env.BUILD_LIST.startsWith('external')) {
				archiveFile("**/Dockerfile.*", true)
			}
		}

		if (params.CODE_COVERAGE) {
			echo "Archive Code Coverage Report"
			def code_coverage_report_tar_name = "${output_name}_code_coverage_report${suffix}"
			dir("${WORKSPACE}/openjdkbinary/j2sdk-image") {
				if (tar_cmd.startsWith('tar')) {
					sh "${tar_cmd} - ${pax_opt} codeCoverageInfoFinal.info code_coverage_report ${tar_cmd_suffix} > ${code_coverage_report_tar_name}"
				} else {
					sh "${tar_cmd} ${code_coverage_report_tar_name} ${pax_opt} codeCoverageInfoFinal.info code_coverage_report ${tar_cmd_suffix}"
				}
			}
			if (!params.ARTIFACTORY_SERVER) {
				echo "ARTIFACTORY_SERVER is not set. Saving artifacts on jenkins."
				archiveArtifacts artifacts: code_coverage_report_tar_name, fingerprint: true, allowEmptyArchive: true
			} else {
				def pattern = "${env.WORKSPACE}/*_code_coverage_report.*"
				uploadToArtifactory(pattern)
			}
		}
		addFailedTestsGrinderLink()
	}
}

def testBuild() {
	TIME_LIMIT =  params.TIME_LIMIT ? params.TIME_LIMIT.toInteger() : 10
	timeout(time: TIME_LIMIT, unit: 'HOURS') {
		try {
			addJobDescription()
			setup()
			addGrinderLink()
			// prepare environment and compile test projects
			if ((params.PARALLEL == "NodesByIterations" && NUM_MACHINES > 1)
				|| (params.PARALLEL == "Dynamic" && (NUM_MACHINES > 1 || (params.TEST_TIME && !params.NUM_MACHINES)))) {
				setupParallelEnv()
			} else {
				testExecution()
			}
		} finally {
			// Terminate any left over test job processes
			terminateTestProcesses()

			if (!params.KEEP_WORKSPACE) {
				forceCleanWS()
				// clean up remaining core files
				if (PLATFORM.contains("mac")) {
					sh "find /cores -name '*core*' -print 2>/dev/null -exec rm -f {} \\; || true"
				} else if (PLATFORM.contains("windows")) {
					sh "find /cygdrive/c/temp -name '*core*' -print 2>/dev/null -exec rm -f {} \\; || true"
				} else {
					sh "find /tmp -name '*core*' -print 2>/dev/null -exec rm -f {} \\; || true"
				}
			}
		}
	}
}

def testExecution() {
	try {
		//ToDo: temporary workaround for jck test parallel runs
		// until build.xml is added into each subfolder
		if( env.BUILD_LIST.startsWith('jck/')) {
			def temp = env.BUILD_LIST
			env.BUILD_LIST = "jck"
			buildTest()
			env.BUILD_LIST = temp
		} else {
			buildTest()
		}
		if(env.BUILD_LIST.startsWith('jck') && !env.SPEC.startsWith('zos')) {
			sshagent(credentials:["${params.JENKINS_KEY}"], ignoreMissing: true) {
				runTest()
			}
		} else {
			runTest()
		}
	} finally {
		post("${env.BUILD_LIST}")
	}
}

def terminateTestProcesses() {
	echo "PROCESSCATCH: Terminating any hung/left over test processes:"

        def statusCode=sh(script:"aqa-tests/terminateTestProcesses.sh ${env.USER} 2>&1", returnStatus:true)
        if (statusCode != 0) {
                echo "rc = ${statusCode}, Unable to terminate all processes."
        }
}

def getJDKImpl(jvm_version) {
	def jdk_impl = 'hotspot'
	if (jvm_version.contains('openj9')) {
		jdk_impl = 'openj9'
	} else if (JVM_VERSION.contains('sap')) {
		jdk_impl = 'sap'
	}
	return jdk_impl
}

def addJobDescription() {
	if (params.PERSONAL_BUILD) {
		// update build name if personal build
		wrap([$class: 'BuildUser']) {
			currentBuild.displayName = "#${BUILD_NUMBER} - ${BUILD_USER_EMAIL}"
		}
	}
	def description = (currentBuild.description) ? currentBuild.description + "<br>" : ""
	currentBuild.description = description \
		+ "TARGET: ${params.TARGET}<br/>" \
		+ "LABEL: <a href=${JENKINS_URL}label/${LABEL}>${LABEL}</a><br/>" \
		+ "<a href=${JENKINS_URL}computer/${NODE_NAME}>${NODE_NAME}</a>"
}

def getJenkinsDomain() {
	String regex = env.JENKINS_URL
	def m = regex =~ /:\/\/(.*)\/?/
	def match = m[0][1]
	def domainName = "undefined"
	if (match) {
		domainName = match
	}
	return domainName
}

def archiveAQAvitFiles() {
	if (params.USE_TESTENV_PROPERTIES && !JOB_NAME.contains("_testList_")) {
		if (params.ARTIFACTORY_SERVER) {
			def currentDate = new Date()
			def currentDateTime = currentDate.format("yyyyMMddHHmmss", TimeZone.getTimeZone('UTC'))
			def uploadDir = "AQAvit/${JDK_IMPL}/${ADOPTOPENJDK_BRANCH}/${JDK_VERSION}/${PLATFORM}/${currentDateTime}"
			uploadToArtifactory("${env.WORKSPACE}/**/*.tap", uploadDir)
		}
	}
}

// If forceStoreOnJenkins set to true, archive on Jenkins.
// If forceStoreOnJenkins set to false, archive on Artifactory if ARTIFACTORY_SERVER is provided. Otherwise, archive on Jenkins
def archiveFile(filename, forceStoreOnJenkins) {
	if (!params.ARTIFACTORY_SERVER || forceStoreOnJenkins) {
		echo "Saving ${filename} file on jenkins."
		archiveArtifacts artifacts: filename, fingerprint: true, allowEmptyArchive: true
	}
	if (params.ARTIFACTORY_SERVER) {
		def pattern = "${env.WORKSPACE}/${filename}"
		uploadToArtifactory(pattern)
	}
}

def uploadToArtifactory(pattern, artifactoryUploadDir="") {
	if (params.ARTIFACTORY_SERVER) {
		def server = Artifactory.server params.ARTIFACTORY_SERVER
		def artifactoryRepo = params.ARTIFACTORY_REPO ? params.ARTIFACTORY_REPO : "sys-rt-generic-local"

		if (artifactoryRepo.contains(',')) {
			String[] repos = artifactoryRepo.split(",")
			artifactoryRepo = repos[0].trim()
		}

		def artifactoryRoorDir = params.ARTIFACTORY_ROOT_DIR ? params.ARTIFACTORY_ROOT_DIR : getJenkinsDomain()
		if (artifactoryRoorDir.endsWith("/")) {
			artifactoryRoorDir = artifactoryRoorDir.substring(0, artifactoryRoorDir.length() - 1);
		}
		def fullUploadPath = "${artifactoryRepo}/${artifactoryRoorDir}/${JOB_NAME}/${BUILD_ID}/"
		if (artifactoryUploadDir) {
			fullUploadPath = "${artifactoryRepo}/${artifactoryRoorDir}/${artifactoryUploadDir}/"
		}

		def uploadSpec = """{
			"files":[
					{
						"pattern": "${pattern}",
						"target": "${fullUploadPath}"
					}
				]
			}"""

		def buildInfo = Artifactory.newBuildInfo()

		if (artifactoryUploadDir && artifactoryUploadDir.contains("AQAvit")) {
			buildInfo.name = "sys-rt/AQAvit_" + buildInfo.name
		} else {
			buildInfo.name = "sys-rt/" + buildInfo.name
			def numArtifacts = params.ARTIFACTORY_NUM_ARTIFACTS ?: -1
			def numDays = 20
			if (params.ARTIFACTORY_NUM_DAYS) {
				numDays = params.ARTIFACTORY_NUM_DAYS
			} else {
				if (ARTIFACTORY_SERVER.contains("ci-eclipse-openj9")) {
					if (JOB_NAME.contains("Grinder")) {
						numDays = 7
					} else {
						numDays = 25
					}
				} else {
					if (JOB_NAME.contains("Grinder")) {
						numDays = 20
					} else {
						numDays = 45
					}
				}
			}
			buildInfo.retention maxBuilds: numArtifacts, maxDays: numDays, deleteBuildArtifacts: true
		}
		server.upload spec: uploadSpec, buildInfo: buildInfo
		server.publishBuildInfo buildInfo

		def artifactoryUrl = server.getUrl()
		def uploadUrl = "${artifactoryUrl}/${fullUploadPath}"
		if (!currentBuild.description.contains(uploadUrl)) {
			if (uploadUrl.contains("AQAvit")) {
				echo "AQAvit files artifactory URL:'${uploadUrl}'"
				currentBuild.description += "<br><a href=${uploadUrl}>AQAvit Artifacts</a>"
			} else {
				echo "Test output artifactory URL:'${uploadUrl}'"
				currentBuild.description += "<br><a href=${uploadUrl}>Artifacts</a>"
			}
		}
	} else {
		echo "ARTIFACTORY_SERVER is not set. Artifacts are not uploaded onto artifactory server."
	}
}

def addGrinderLink() {
	String url = "${HUDSON_URL}job/Grinder/parambuild/?"
	int i = 1;
	def labelValue = ""
	def targetValue = ""
	def customTargetKeyValue = ""
	def rerunIterations = ""
	def urlParams = params.findAll {
		// Exclude separator and help text parameters from url
		!(it.key.endsWith('_PARAMS') || it.key.endsWith('_HELP_TEXT'))
	}
	urlParams.each { key, value ->
		value = URLEncoder.encode(value.toString(), "UTF-8")
		url += "${key}=${value}"
		if (i != urlParams.size()) {
			url += "&amp;"
		}
		i++;
		if ( key == "LABEL" ) {
			labelValue = "LABEL=${value}"
		}
		if ( key == "TARGET" ) {
			targetValue = "TARGET=${value}"
		}
		if ( key == "CUSTOM_TARGET") {
			customTargetKeyValue = "CUSTOM_TARGET=${value}"
		}
		if ( key == "RERUN_ITERATIONS") {
			rerunIterations = "RERUN_ITERATIONS=${value}"
		}

	}
	env.RERUN_LINK = url
	env.FAILED_TEST_TARGET = targetValue
	env.CUSTOM_TARGET_KEY_VALUE = customTargetKeyValue

	// reset RERUN_ITERATIONS to 0 in Rerun in Grinder link
	if (rerunIterations) {
		url = url.replace(rerunIterations,"RERUN_ITERATIONS=0")
	}

	currentBuild.description += "<br><a href=\"https://github.com/adoptium/aqa-tests/wiki/How-to-Run-a-Grinder-Build-on-Jenkins\">Grinder Wiki</a>"
	echo "Rerun in Grinder: ${url}"
	currentBuild.description += "<br><a href=${url}>Rerun in Grinder</a> Change TARGET to run only the failed test targets."
	def sameMachineUrl = url.replace(labelValue,"LABEL=${NODE_NAME}")
	echo "Rerun in Grinder on same machine: ${sameMachineUrl}"
	currentBuild.description += "<br><a href=${sameMachineUrl}>Rerun in Grinder on same machine</a> Change TARGET to run only the failed test targets. For dynamic vm agents as they are created at runtime and quickly recycled, it may not be possible to rerun on the same agent."
}

def addFailedTestsGrinderLink(paths=""){
	if (currentBuild.result == 'UNSTABLE' || currentBuild.result == 'FAILURE' || currentBuild.result == 'ABORTED') {
		def failedTestList = ""
		def jdkFailedTestCaseList = ""
		def hotspotFailedTestCaseList = ""
		List<String> buildPaths = paths.split(',')
		for (def buildPath: buildPaths) {
			def tapFiles = findFiles(glob: "${buildPath}**/*.tap")
			for (def tapFile: tapFiles) {
				echo "Tap file found: ${tapFile}..."
				def file = readFile(file: "${tapFile}")
				TapConsumer tapConsumer = TapConsumerFactory.makeTap13YamlConsumer()
				TestSet testSet = tapConsumer.load(file)
				for (int i = 1; i <= testSet.getNumberOfTestResults(); i++) {
					if (!testSet.getTestResult(i).getStatus().toString().equals("ok")) {
						def failedtest = testSet.getTestResult(i).getDescription().trim().substring(2)
						failedTestList += "${failedtest},"
						if (env.BUILD_LIST.contains('openjdk')) {
							def failedTestCasesInfo = testSet.getTestResult(i).getDiagnostic().get("output").toString()
							if (failedTestCasesInfo.contains("Failed test cases:") && failedTestCasesInfo.contains("Test results:")) {
								failedTestCasesInfo = failedTestCasesInfo.substring(failedTestCasesInfo.indexOf('TEST:'))
								failedTestCasesInfo = failedTestCasesInfo.substring(0, failedTestCasesInfo.indexOf('Test results:'))
								failedTestCasesInfo = failedTestCasesInfo.split("\\n").join(" ").replaceAll("TEST: ", "")
								// Remove #id suffixed to the openjdk testcase name. Jtreg doesn't work with it.
								failedTestCasesInfo = failedTestCasesInfo.replaceAll(/#id\d{1,}/, "")
								if (failedtest.startsWith("jdk_")) {
									jdkFailedTestCaseList += "${failedTestCasesInfo} "
								} else {
									hotspotFailedTestCaseList += "${failedTestCasesInfo} "
								}
							}
						}
					}
				}
			}
		}
		if (failedTestList) {
			String failedTests = failedTestList.substring(0, failedTestList.length() - 1)
			env.FAILED_TESTS= failedTests ?: ""
			failedTestList = "testList+TESTLIST=" + failedTests
			String url = env.RERUN_LINK
			def failedTestUrl = url.replace(env.FAILED_TEST_TARGET, "TARGET=$failedTestList")
			echo "Rerun in Grinder with failed test targets: ${failedTestUrl}"
			currentBuild.description += "<br><a href=${failedTestUrl}> Rerun in Grinder with failed test targets</a>"
			def customizedTestCases = [:]
			if (jdkFailedTestCaseList) {
				customizedTestCases['jdk'] = "${jdkFailedTestCaseList}"
			}
			if (hotspotFailedTestCaseList) {
				customizedTestCases['hotspot'] = "${hotspotFailedTestCaseList}"
			}
			customizedTestCases.each { target, testcases ->
				def tempTestCases = testcases.substring(0, testcases.length() - 1)
				tempTestCases = tempTestCases.split(' ').toUnique().join('+')
				def customURL = url.replace(env.FAILED_TEST_TARGET, "TARGET=${target}_custom")
				customURL = customURL.replace(env.CUSTOM_TARGET_KEY_VALUE, "CUSTOM_TARGET=$tempTestCases")
				echo "Rerun failed ${target} test cases in Grinder with ${target}_custom target: ${customURL}"
				currentBuild.description += "<br><a href=${customURL}> Rerun failed ${target} test cases in Grinder with ${target}_custom target</a>"
			}
		}
	}
}

def generateJob (newJobs, childTest, testJobName) {
	// If GENERATE_JOBS is set to true, force generate the child job. Otherwise, only generate the child job if it does not exist
	if (params.GENERATE_JOBS) {
		newJobs[childTest] = {
			echo "GENERATE_JOBS is set to true, set test job ${testJobName} params for generating the job"
			createJob(testJobName, PLATFORM)
		}
	} else {
		def jobIsRunnable = false
		try {
			def JobHelper = library(identifier: 'openjdk-jenkins-helper@master').JobHelper
			jobIsRunnable = JobHelper.jobIsRunnable("${testJobName}")
			echo "${testJobName} jobIsRunnable: ${jobIsRunnable}"
		} catch (Exception e) {
			echo "Cannot call jobIsRunnable() from openjdk-jenkins-helper@master. Skipping..."
		}
		if (!jobIsRunnable) {
			newJobs[childTest] = {
				echo "Test job ${testJobName} doesn't exist, set test job ${testJobName} params for generating the job"
				createJob(testJobName, PLATFORM)
			}
		}
	}
}
def triggerRerunJob () {
	// if the JOB_NAME contains _rerun or _testList_, we will not trigger rerun job
	if (!JOB_NAME.contains("_rerun") && !JOB_NAME.contains("_testList_") && !JOB_NAME.contains("_iteration_")) {
		int rerunIterations = params.RERUN_ITERATIONS ? params.RERUN_ITERATIONS.toInteger() : 0
		if (rerunIterations > 0 && env.FAILED_TESTS?.trim()) {
			stage('Rerun') {
				def rerunJobName = "${JOB_NAME}_rerun"
				def newJobs = [:]
				def childParams = []
				echo "allocate a node for generating rerun job ..."
				node {
					generateJob(newJobs, rerunJobName, rerunJobName)
					parallel newJobs

					// loop through all the params and change the parameters if needed
					params.each { param ->
						// set PARALLEL, NUM_MACHINES and TEST_TIME to default values
						// set TARGET to failed tests and set ITERATIONS to rerunIterations
						if (param.key == "TARGET") {
							childParams << string(name: param.key, value: "testList TESTLIST=" + env.FAILED_TESTS)
						} else if (param.key == "PARALLEL") {
							childParams << string(name: param.key, value: "None")
						} else if (param.key == "NUM_MACHINES") {
							childParams << string(name: param.key, value: "")
						} else if (param.key == "TEST_TIME") {
							childParams << string(name: param.key, value: "")
						} else if (param.key == "ITERATIONS") {
							childParams << string(name: param.key, value: rerunIterations.toString())
						} else {
							def value = param.value.toString()
							if (value == "true" || value == "false") {
								childParams << booleanParam(name: param.key, value: value.toBoolean())
							} else {
								childParams << string(name: param.key, value: value)
							}
						}
					}
				}

				if (childParams) {
					build job: rerunJobName, parameters: childParams, propagate: false
				}
			}
		}
	}
}

def run_parallel_tests() {
	if (params.PARALLEL && params.PARALLEL != "None" && (NUM_MACHINES > 1 || params.TEST_TIME)) {
		stage ("Parallel Tests") {
			def childJobs = parallel parallel_tests
			node {
				forceCleanWS()
				try {
					def buildPaths = ""
					childJobs.each {
						cjob ->
							def jobInvocation = cjob.value.getRawBuild()
							def buildId = jobInvocation.getNumber()
							def name = cjob.value.getProjectName()
							def childResult = cjob.value.getCurrentResult()
							try {
								echo "${name} #${buildId} completed with status ${childResult}"
								timeout(time: 1, unit: 'HOURS') {
									copyArtifacts (projectName: "${name}", selector: specific("${buildId}"), filter: "**/*.tap", target:"${name}/${buildId}")
								}
								step([$class: "TapPublisher", testResults: "${name}/${buildId}/**/*.tap", outputTapToConsole: false, failIfNoResults: true])
								archiveFile("${name}/${buildId}/**/*.tap", true)
								buildPaths += "${name}/${buildId}/,"
							} catch (Exception e) {
								echo 'Exception: ' + e.toString()
								echo "Cannot copy *.tap or AQACert.log from ${name} with buildid ${buildId} . Skipping copyArtifacts..."
							}
							if (!currentBuild.resultIsWorseOrEqualTo(childResult)) {
								currentBuild.result = childResult;
							}
					}

					def resultSum = parseResultSumFromTaps()
					checkTestResults(resultSum)

					archiveAQAvitFiles()
					if (buildPaths.length() > 0) {
						addFailedTestsGrinderLink(buildPaths.substring(0, buildPaths.length() - 1))
					}
				} finally {
					forceCleanWS()
				}
			}
		}
	}
}

def parseResultSumFromTaps() {
	def results = [:]
	def tapFiles = findFiles(glob: "**/*.tap")
	for (String tapFile : tapFiles) {
		def tap = readFile(file: "${tapFile}")
		def lines = tap.readLines()
		def found = false
		for (String line : lines) {
			if ((match = line =~ /# RESULTS_SUMMARY: (TOTAL: \d+)\s*(EXECUTED: \d+)\s*(PASSED: \d+)\s*(FAILED: \d+)\s*(DISABLED: \d+)\s*(SKIPPED: \d+)/)) {
				for (int i = 1; i < match.groupCount(); i++) {
					def matchVals = match.group(i).split(": ")
					if (!results[matchVals[0]]) {
						results[matchVals[0]] = 0;
					}
					results[matchVals[0]] += matchVals[1] as int
				}
				found = true
				break
			}
		}
		if (!found) {
			return [:]
		}
	}
	return results
}

def getGitRepoBranch(ownerBranch, defaultOwnerBranch, repo) {
	String[] actualRepoBranch = defaultOwnerBranch.split(":")
	if (ownerBranch) {
		String[] tokens = ownerBranch.split(":")
		if (tokens.size() == 2 ) {
			actualRepoBranch = tokens;
		} else {
			error "[ERROR]: Wrong format of XXX_OWNER_BRANCH value: ${ownerBranch}. The expected format is [owner]:[branch]"
		}
	}

	String owner = actualRepoBranch[0].trim()
	String repoURL = "https://github.com/${owner}/${repo}.git"
	if (env.SPEC.startsWith('zos')) {
		repoURL = repoURL.replace("https://github.com/","git@github.com:")
	}
	actualRepoBranch[0] = repoURL
	actualRepoBranch[1] = actualRepoBranch[1].trim()
	return actualRepoBranch
}

def forceCleanWS() {
	try {
		cleanWs disableDeferredWipeout: true, deleteDirs: true
	} catch (Exception e) {
		echo 'Exception: ' + e.toString()
		//cleanWs has issue to delete workspace that contains non-ASCII filename in TKG output https://issues.jenkins.io/browse/JENKINS-33478
		//cannot delete workspace directly. Otherwise, Jenkins job will abort due to missing workspace
		sh "rm -rf ${env.WORKSPACE}/aqa-tests/TKG"
		// call cleanWs() again
		cleanWs disableDeferredWipeout: true, deleteDirs: true
	}
}

return this
