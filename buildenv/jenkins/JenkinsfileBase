#!groovy
import org.tap4j.consumer.TapConsumer;
import org.tap4j.consumer.TapConsumerFactory;
import org.tap4j.model.TestSet;

def makeTest(testParam) {
	String tearDownCmd = "$RESOLVED_MAKE; \$MAKE -f ./aqa-tests/TKG/testEnv.mk testEnvTeardown"
	// Note: keyword source cannot be used in Jenkins script. Therefore, using "." instead.
	String makeTestCmd = "$RESOLVED_MAKE;cd ./aqa-tests; . ./scripts/testenv/testenvSettings.sh;cd ./TKG; \$MAKE $testParam"
	//unset LD_LIBRARY_PATH workaround for issue https://github.com/adoptium/infrastructure/issues/2934
	if (JDK_IMPL == 'hotspot' && PLATFORM.contains('alpine-linux')) {
		makeTestCmd = "unset LD_LIBRARY_PATH; $makeTestCmd"
	}
	try {
		sh "$tearDownCmd"
		if (env.DOCKER_REGISTRY_URL && env.DOCKER_REGISTRY_URL_CREDENTIAL_ID && env.BASE_DOCKER_REGISTRY_CREDENTIAL_ID) {
			withCredentials([
				usernamePassword(credentialsId: "${env.DOCKER_REGISTRY_URL_CREDENTIAL_ID}", usernameVariable: 'DOCKER_REGISTRY_CREDENTIALS_USR', passwordVariable: 'DOCKER_REGISTRY_CREDENTIALS_PSW'),
				usernamePassword(credentialsId: "${env.BASE_DOCKER_REGISTRY_CREDENTIAL_ID}", usernameVariable: 'BASE_DOCKER_REGISTRY_CREDENTIAL_USR', passwordVariable: 'BASE_DOCKER_REGISTRY_CREDENTIAL_PSW')
			]) {
				sh "$makeTestCmd"
			}
		} else if (env.DOCKER_REGISTRY_URL && env.DOCKER_REGISTRY_URL_CREDENTIAL_ID) {
			withCredentials([
				usernamePassword(credentialsId: "${env.DOCKER_REGISTRY_URL_CREDENTIAL_ID}", usernameVariable: 'DOCKER_REGISTRY_CREDENTIALS_USR', passwordVariable: 'DOCKER_REGISTRY_CREDENTIALS_PSW'),
			]) {
				sh "$makeTestCmd"
			}
		} else {
			sh "$makeTestCmd"
		}
	} catch (err) {
		currentBuild.result = 'UNSTABLE'
	} finally {
		sh "$tearDownCmd"
	}
}

def setupEnv() {
	env.JOBSTARTTIME = sh(script: 'LC_TIME=C date +"%a, %d %b %Y %T %z"', returnStdout: true).trim()

	// Terminate any previous test related processes that are running
	terminateTestProcesses()

	if ( params.JDK_VERSION ) {
		env.ORIGIN_JDK_VERSION = params.JDK_VERSION
		env.JDK_VERSION = params.JDK_VERSION.equalsIgnoreCase("next") ? "" : params.JDK_VERSION
	}
	env.USE_TESTENV_PROPERTIES = params.USE_TESTENV_PROPERTIES

	env.SPEC = "${SPEC}"
	if(!params.USE_TESTENV_PROPERTIES){
		env.ADOPTOPENJDK_REPO = params.ADOPTOPENJDK_REPO ? params.ADOPTOPENJDK_REPO : "https://github.com/adoptium/aqa-tests.git"
		OPENJ9_REPO = params.OPENJ9_REPO ? params.OPENJ9_REPO : "https://github.com/eclipse-openj9/openj9.git"
		String[] tkg = getGitRepoBranch(params.TKG_OWNER_BRANCH, "adoptium:master", "TKG")
		TKG_REPO = tkg[0]
		TKG_BRANCH = tkg[1]
		//For Zos, the right repo should be something like: git@github.ibm.com:runtimes/openj9-openjdk-jdk**-zos.git and for now there is only jdk11
		env.JDK_REPO = params.JDK_REPO ? params.JDK_REPO : ""
		if (env.SPEC.startsWith('zos')) {
			env.ADOPTOPENJDK_REPO = env.ADOPTOPENJDK_REPO.replace("https://github.com/","git@github.com:")
			OPENJ9_REPO = OPENJ9_REPO.replace("https://github.com/","git@github.com:")
		}
		OPENJ9_BRANCH = params.OPENJ9_BRANCH ? params.OPENJ9_BRANCH : "master"
	}

	PLATFORM = params.PLATFORM ? params.PLATFORM : ""
	env.ADOPTOPENJDK_BRANCH = params.ADOPTOPENJDK_BRANCH ? params.ADOPTOPENJDK_BRANCH : "master"
	CLONE_OPENJ9 = params.CLONE_OPENJ9 ? params.CLONE_OPENJ9 : "true"
	CUSTOM_TARGET = params.CUSTOM_TARGET ? params.CUSTOM_TARGET : ""
	UPSTREAM_JOB_NAME = params.UPSTREAM_JOB_NAME ? params.UPSTREAM_JOB_NAME : ""
	UPSTREAM_JOB_NUMBER = params.UPSTREAM_JOB_NUMBER ? params.UPSTREAM_JOB_NUMBER : ""
	SSH_AGENT_CREDENTIAL = params.SSH_AGENT_CREDENTIAL ? params.SSH_AGENT_CREDENTIAL : ""
	KEEP_WORKSPACE = params.KEEP_WORKSPACE ? params.KEEP_WORKSPACE : false
	OPENJ9_SHA = params.OPENJ9_SHA ? params.OPENJ9_SHA : ""
	CLOUD_PROVIDER = params.CLOUD_PROVIDER ? params.CLOUD_PROVIDER : ""
	env.JDK_BRANCH = params.JDK_BRANCH ? params.JDK_BRANCH : ""
	env.USER_CREDENTIALS_ID = params.USER_CREDENTIALS_ID ? params.USER_CREDENTIALS_ID : ""
	env.TEST_JDK_HOME = "$WORKSPACE/jdkbinary/j2sdk-image"
	env.JVM_VERSION = params.JVM_VERSION ? params.JVM_VERSION : ""
	env.JVM_OPTIONS = params.JVM_OPTIONS ? params.JVM_OPTIONS : ""
	env.APPLICATION_OPTIONS = params.APPLICATION_OPTIONS ? params.APPLICATION_OPTIONS : ""
	env.EXTRA_DOCKER_ARGS = params.EXTRA_DOCKER_ARGS ? params.EXTRA_DOCKER_ARGS : ""
	env.OPENJDK_SHA = params.OPENJDK_SHA ? params.OPENJDK_SHA : ""
	env.OPENLIBERTY_SHA = params.OPENLIBERTY_SHA ? params.OPENLIBERTY_SHA : ""
	env.TEST_FLAG = params.TEST_FLAG ? params.TEST_FLAG : ''
	env.KEEP_REPORTDIR = params.KEEP_REPORTDIR ? params.KEEP_REPORTDIR : false
	SDK_RESOURCE = params.SDK_RESOURCE ? params.SDK_RESOURCE : "upstream"
	env.AUTO_DETECT = params.AUTO_DETECT
	env.EXTERNAL_CUSTOM_REPO=params.EXTERNAL_CUSTOM_REPO? params.EXTERNAL_CUSTOM_REPO : ""
	env.EXTERNAL_REPO_BRANCH=params.EXTERNAL_REPO_BRANCH ? params.EXTERNAL_REPO_BRANCH : "master"
	env.EXTERNAL_TEST_CMD=params.EXTERNAL_TEST_CMD ? params.EXTERNAL_TEST_CMD : "mvn clean install"
	env.DYNAMIC_COMPILE=params.DYNAMIC_COMPILE ? params.DYNAMIC_COMPILE : false
	env.USE_JRE=params.USE_JRE ? params.USE_JRE : false
	env.RERUN_LINK = ""
	env.FAILED_TESTS = ""
	env.FAILED_TEST_TARGET = ""
	env.CUSTOM_TARGET_KEY_VALUE =""
	env.DOCKER_REGISTRY_URL = params.DOCKER_REGISTRY_URL ? params.DOCKER_REGISTRY_URL : ""
	env.DOCKER_REGISTRY_DIR = params.DOCKER_REGISTRY_DIR ? params.DOCKER_REGISTRY_DIR : ""
	env.DOCKER_REGISTRY_URL_CREDENTIAL_ID = params.DOCKER_REGISTRY_URL_CREDENTIAL_ID ? params.DOCKER_REGISTRY_URL_CREDENTIAL_ID : ""
	env.BASE_DOCKER_REGISTRY_CREDENTIAL_ID = params.BASE_DOCKER_REGISTRY_CREDENTIAL_ID ? params.BASE_DOCKER_REGISTRY_CREDENTIAL_ID : ""
	ITERATIONS = params.ITERATIONS ? "${params.ITERATIONS}".toInteger() : 1
	env.TKG_ITERATIONS = params.TKG_ITERATIONS ? "${params.TKG_ITERATIONS}".toInteger() : 1
	env.EXIT_FAILURE = params.EXIT_FAILURE ? params.EXIT_FAILURE : false
	env.EXIT_SUCCESS = params.EXIT_SUCCESS ? params.EXIT_SUCCESS : false
	NUM_MACHINES = params.NUM_MACHINES ? params.NUM_MACHINES.toInteger() : 1
	env.LIB_DIR = JOB_NAME.contains("SmokeTests") ? "${WORKSPACE}/../../../../../testDependency/lib" : "${WORKSPACE}/../../testDependency/lib"
	env.SYSTEM_LIB_DIR = JOB_NAME.contains("SmokeTests") ? "${WORKSPACE}/../../../../../testDependency/system_lib" : "${WORKSPACE}/../../testDependency/system_lib"
	env.OPENJCEPLUS_GIT_REPO = params.OPENJCEPLUS_GIT_REPO ?: "https://github.com/ibmruntimes/OpenJCEPlus.git"
	env.OPENJCEPLUS_GIT_BRANCH = params.OPENJCEPLUS_GIT_BRANCH ?: "semeru-java${params.JDK_VERSION}"

	env.LIGHT_WEIGHT_CHECKOUT = (params.LIGHT_WEIGHT_CHECKOUT == false) ? params.LIGHT_WEIGHT_CHECKOUT : true
	env.GENERATE_JOBS = params.GENERATE_JOBS ?: false

	if (JOB_NAME.contains("Grinder")) {
		def currentDate = new Date()
		def currentDateTime = currentDate.format("yyyyMMddHHmmss", TimeZone.getTimeZone('UTC'))
		env.TAP_NAME = "${JOB_NAME}_${currentDateTime}.tap"
		// If personal repo and branch are set, test jobs need to be regenerated (with LIGHT_WEIGHT_CHECKOUT = false)
		// to take personal repo and branch.
		// Therefore, set LIGHT_WEIGHT_CHECKOUTto false and GENERATE_JOBS to true.
		// This is a known Jenkins issue: https://issues.jenkins.io/browse/JENKINS-42971
		if (!env.ADOPTOPENJDK_REPO.contains("adoptium/aqa-tests")) {
			env.LIGHT_WEIGHT_CHECKOUT = false
			env.GENERATE_JOBS = true
			echo "ADOPTOPENJDK_REPO is set to personal repo in Grinder. Auto-set LIGHT_WEIGHT_CHECKOUT: ${env.LIGHT_WEIGHT_CHECKOUT} and GENERATE_JOBS: ${env.GENERATE_JOBS}"
		}
	} else {
		env.TAP_NAME = "${JOB_NAME}.tap"
	}

	if (params.CODE_COVERAGE) {
		// GCOV strips # num from folder path in BUILD pipeline, e.g., /home/jenkins/workspace/Build_JDK11_x86-64_linux_Personal/build/linux-x86_64-normal-server-release/vm
		env.GCOV_PREFIX_STRIP = 1
		env.GCOV_PREFIX = env.TEST_JDK_HOME
	}

	if (params.JRE_IMAGE) {
		env.JRE_IMAGE = "${WORKSPACE}/${params.JRE_IMAGE}"
	}

	if (params.USE_JRE) {
		env.USE_JRE = 1
	}

	if (params.JDK_IMPL) {
		env.JDK_IMPL = params.JDK_IMPL
	} else if (params.JVM_VERSION) {
		env.JDK_IMPL = getJDKImpl(params.JVM_VERSION)
	}

	if( params.PERF_ROOT ) {
		env.PERF_ROOT = params.PERF_ROOT
	} else {
		env.PERF_ROOT = "$WORKSPACE/../../benchmarks"
	}

	env.JCK_VERSION = params.JCK_VERSION ? params.JCK_VERSION : ""
	env.JCK_ROOT = params.JCK_ROOT ? params.JCK_ROOT : ""
	env.JCK_GIT_REPO = params.JCK_GIT_REPO ? params.JCK_GIT_REPO : ""

	env.OCP_SERVER = params.OCP_SERVER ? params.OCP_SERVER : ''
	env.OCP_TOKEN = params.OCP_TOKEN ? params.OCP_TOKEN : ''

	if (env.BUILD_LIST.contains('external')) {
		env.DIAGNOSTICLEVEL ='noDetails'
	}

	if( params.DOCKERIMAGE_TAG ) {
		env.DOCKERIMAGE_TAG = params.DOCKERIMAGE_TAG
	}
	if ( env.SPEC.contains('sunos')) {
		sh 'env'
	} else {
		sh 'printenv'
	}
}

def setupParallelEnv() {
	stage('setupParallelEnv') {
		int NUM_LIST = -1
		def maxChildJobNum = 25
		int childJobNum = 1
		def UPSTREAM_TEST_JOB_NAME = ""
		def UPSTREAM_TEST_JOB_NUMBER = ""
		parallel_tests = [:]

		if (params.PARALLEL == "NodesByIterations") {
			childJobNum = NUM_MACHINES
			// limit childJobNum
			if (childJobNum > 20) {
				echo "Due to the limited machines, NUM_MACHINES can only be set up to 20. Current NUM_MACHINES is ${NUM_MACHINES}."
				echo "Reset NUM_MACHINES to 20..."
				childJobNum = 20
			}
		} else if (params.PARALLEL == "Dynamic") {
			try {
				//get cached TRSS JSON data
				timeout(time: 1, unit: 'HOURS') {
					copyArtifacts fingerprintArtifacts: true, projectName: "getTRSSOutput", selector: lastSuccessful(), target: 'aqa-tests/TKG/resources/TRSS'
					sh "cd ./aqa-tests/TKG/resources/TRSS; gzip -cd TRSSOutput.tar.gz | tar xof -; rm TRSSOutput.tar.gz"
				}
			} catch (Exception e) {
				echo 'Exception: ' + e.toString()
				echo 'Cannot get cached TRSS JSON data. Skipping copyArtifacts...'
			}

			try {
				// check pre-stage test libs on the machine
				// check for each lib. If lib does not exist, donwload it.
				// If lib exists, SHA will be checked. Re-download if SHA does not match.
				timeout(time: 20, unit: 'MINUTES') {
					def customUrl = getCustomUrl()
					if (PLATFORM.contains("windows")) {
						env.LIB_DIR = env.LIB_DIR.replaceAll("\\\\", "/")
						env.SYSTEM_LIB_DIR = env.SYSTEM_LIB_DIR.replaceAll("\\\\", "/")
					}
					if (env.BUILD_LIST == 'system') {
						env.LIB_DIR = env.SYSTEM_LIB_DIR
					}
					sh "perl ./aqa-tests/TKG/scripts/getDependencies.pl -path ${env.LIB_DIR} -task default -customUrl ${customUrl}"
				}
			} catch (Exception e) {
				echo 'Exception: ' + e.toString()
				echo "Cannot pre-stage test libs from ${env.LIB_DIR} on the machine. Skipping..."
			}

			String PARALLEL_OPTIONS = "TEST=${TARGET}"
			if (params.TRSS_URL) {
				PARALLEL_OPTIONS += " TRSS_URL=${params.TRSS_URL}"
			}
			int MAX_NUM_MACHINES = Math.min(20, getMachineLimit());
			if (params.NUM_MACHINES) {
				int numOfMachines = getNumMachines()
				PARALLEL_OPTIONS += " NUM_MACHINES=${numOfMachines} TEST_TIME="
				NUM_LIST = genParallelList(PARALLEL_OPTIONS)
			} else if (params.TEST_TIME) {
				String PARALLEL_OPTIONS_TEMP = PARALLEL_OPTIONS
				PARALLEL_OPTIONS += " TEST_TIME=${params.TEST_TIME} NUM_MACHINES="
				NUM_LIST = genParallelList(PARALLEL_OPTIONS)
				if (NUM_LIST > MAX_NUM_MACHINES) {
					echo "TEST_TIME (${params.TEST_TIME} minutes) is not possible as it exceeds the machine limit."
					echo "Regenerate parallel list with NUM_MACHINES=${MAX_NUM_MACHINES}."
					PARALLEL_OPTIONS = PARALLEL_OPTIONS_TEMP + " NUM_MACHINES=${MAX_NUM_MACHINES} TEST_TIME="
					NUM_LIST = genParallelList(PARALLEL_OPTIONS)
				} else if (NUM_LIST < 6 && env.JDK_IMPL == "openj9" && (TARGET == "extended.jck" || TARGET == "special.system")) {
					echo "NUM_LIST value ${NUM_LIST} may not be calculated based on the actual execution time."
					echo "Regenerate parallel list with NUM_MACHINES=6 for TARGET ${TARGET}."
					PARALLEL_OPTIONS = PARALLEL_OPTIONS_TEMP + " NUM_MACHINES=6 TEST_TIME="
					NUM_LIST = genParallelList(PARALLEL_OPTIONS)
				}
			} else {
				PARALLEL_OPTIONS += " TEST_TIME= NUM_MACHINES="
				NUM_LIST = genParallelList(PARALLEL_OPTIONS)
			}

			if (NUM_LIST > 1) {
				childJobNum = NUM_LIST
				echo "Saving parallelList.mk file on jenkins..."
				dir('aqa-tests/TKG') {
					archiveArtifacts artifacts: 'parallelList.mk', fingerprint: true, allowEmptyArchive: false
				}
			} else if (NUM_LIST == 1) {
				echo " Number of test list is 1, no need to run tests in child job."
				return NUM_LIST
			} else {
				assert false : "Build failed because cannot find NUM_LIST in parallelList.mk file."
			}
		}

		UPSTREAM_TEST_JOB_NAME = JOB_NAME
		UPSTREAM_TEST_JOB_NUMBER = BUILD_NUMBER

		echo "[PARALLEL: ${params.PARALLEL}] childJobNum is ${childJobNum}, creating jobs and running them in parallel..."
		create_jobs = [:]
		parallelTestParams =[:]
		for (int i = 0; i < childJobNum; i++) {
			def buildListName = env.BUILD_LIST
			def childTest = ""
			def childTarget = TARGET
			if (params.PARALLEL == "NodesByIterations") {
				childTest = "iteration_${i}"
			} else if (params.PARALLEL == "Dynamic") {
				childTest = "testList_${i}"
				childTarget = "-f parallelList.mk ${childTest}"
			}
			def TEST_JOB_NAME = "${JOB_NAME}_${childTest}"

			generateJob(create_jobs, childTest, TEST_JOB_NAME)

			def childParams = []
			// loop through all the params and change the parameters if needed
			params.each { param ->
				// set PARALLEL, NUM_MACHINES and TEST_TIME to default values
				if (param.key == "BUILD_LIST") {
					childParams << string(name: param.key, value: "${buildListName}")
				} else if (param.key == "TARGET") {
					childParams << string(name: param.key, value: "${childTarget}")
				} else if (param.key == "PARALLEL") {
					childParams << string(name: param.key, value: "None")
				} else if (param.key == "NUM_MACHINES") {
					childParams << string(name: param.key, value: "")
				} else if (param.key == "TEST_TIME") {
					childParams << string(name: param.key, value: "")
				} else {
					def value = param.value.toString()
					if (value == "true" || value == "false") {
						childParams << booleanParam(name: param.key, value: value.toBoolean())
					} else {
						childParams << string(name: param.key, value: value)
					}
				}
			}

			childParams << string(name: 'UPSTREAM_TEST_JOB_NAME', value: UPSTREAM_TEST_JOB_NAME)
			childParams << string(name: 'UPSTREAM_TEST_JOB_NUMBER', value: UPSTREAM_TEST_JOB_NUMBER)

			parallel_tests[childTest] = {
				build job: TEST_JOB_NAME, parameters: childParams, propagate: false
			}
			parallelTestParams[TEST_JOB_NAME] = childParams
		}

		if (create_jobs) {
			parallel create_jobs
		}
		return NUM_LIST
		// return to top level pipeline file in order to exit node block before running tests in parallel
	}
}

// Returns NUM_LIST from parallelList.mk.
// NUM_LIST can be different than numOfMachines.
def genParallelList(PARALLEL_OPTIONS) {
	String unsetLLP = ""
	//unset LD_LIBRARY_PATH workaround for issue https://github.com/adoptium/infrastructure/issues/2934
	if (JDK_IMPL == 'hotspot' && PLATFORM.contains('alpine-linux')) {
		unsetLLP = "unset LD_LIBRARY_PATH;"
	}
	sh "cd ./aqa-tests/TKG; $RESOLVED_MAKE; ${unsetLLP} \$MAKE genParallelList ${PARALLEL_OPTIONS}"
	def parallelList = "aqa-tests/TKG/parallelList.mk"
	int NUM_LIST = -1
	if (fileExists("${parallelList}")) {
		if (SPEC.startsWith('zos')) {
			echo 'Converting parallelList.mk file from ebcdic to ascii...'
			sh "iconv -f ibm-1047 -t iso8859-1 ${parallelList} > ${parallelList}.ascii; rm ${parallelList}; mv ${parallelList}.ascii ${parallelList}"
		}
		echo "read parallelList.mk file: ${parallelList}"
		def properties = readProperties file: "${parallelList}"
		if (properties.NUM_LIST) {
			NUM_LIST = properties.NUM_LIST.toInteger()
		}
	}
	return NUM_LIST
}

// Returns num
// num = params.NUM_MACHINES. If it is not provided, the default value is 1
// num cannot be greater than machines limit
def getNumMachines() {
	int num = params.NUM_MACHINES ? params.NUM_MACHINES.toInteger() : 1
	int limit = getMachineLimit()
	echo "machine limit is ${limit}"
	if (num > limit) {
		echo "Number of machines cannot be greater than ${limit}. Set num to ${limit}"
		num = limit
	}
	return num
}

def getMachineLimit(){
	int limit = nodesByLabel(LABEL).size()
	// Set limit for dynamic vm agents to 100
	if (LABEL.contains('ci.agent.dynamic')) {
		limit = 100
	}
	return limit
}

def createJob( TEST_JOB_NAME, ARCH_OS ) {

	def jobParams = [:]
	jobParams.put('TEST_JOB_NAME', TEST_JOB_NAME)
	jobParams.put('ARCH_OS_LIST', ARCH_OS)

	if (params.DAYS_TO_KEEP) {
		jobParams.put('DAYS_TO_KEEP', DAYS_TO_KEEP)
	}

	if (params.BUILDS_TO_KEEP) {
		jobParams.put('BUILDS_TO_KEEP', BUILDS_TO_KEEP)
	}

	//get level and group if TEST_JOB_NAME matches the format of Test_openjdk11_j9_extended.functional_ppc64_aix
	//otherwise, use default level and group value in template
	if (TEST_JOB_NAME.startsWith("Test_openjdk")) {
		def level = ""
		def group = ""
		def tokens = TEST_JOB_NAME.split('_');
		if (tokens.size() > 3 && tokens[3].contains(".")) {
			level = tokens[3].split("\\.")[0]
			group = tokens[3].split("\\.")[1]
		}

		if (level && group) {
			jobParams.put('LEVELS', level)
			jobParams.put('GROUPS', group)
		}
	}

	def templatePath = 'aqa-tests/buildenv/jenkins/testJobTemplate'
	if (!fileExists(templatePath)) {
		sh "curl -Os https://raw.githubusercontent.com/adoptium/aqa-tests/master/buildenv/jenkins/testJobTemplate"
		templatePath = 'testJobTemplate'
	}

	if (env.LIGHT_WEIGHT_CHECKOUT) {
		jobParams.put('LIGHT_WEIGHT_CHECKOUT', env.LIGHT_WEIGHT_CHECKOUT)
	}

	def create = jobDsl targets: templatePath, ignoreExisting: false, additionalParameters: jobParams
	return create
}

def setup() {
	stage('Setup') {
		setupEnv()
		if (params.CUSTOMIZED_SDK_URL) {
			if (params.SDK_RESOURCE == 'nightly' || params.SDK_RESOURCE == 'releases') {
				// remove single quote to allow variables to be set in CUSTOMIZED_SDK_URL
				CUSTOMIZED_SDK_URL_OPTION = "-c ${params.CUSTOMIZED_SDK_URL}"
			} else if (!params.SDK_RESOURCE || params.SDK_RESOURCE == 'customized') {
				SDK_RESOURCE = "customized"
				CUSTOMIZED_SDK_URL_OPTION = "-c '${params.CUSTOMIZED_SDK_URL}'"
				if (params.ADDITIONAL_ARTIFACTS_REQUIRED == "RI_JDK") {
					def server = Artifactory.server params.ARTIFACTORY_SERVER
					def artifactoryUrl = server.getUrl()
					def repoForRi = ''
					def riURL = ''
					if (params.ARTIFACTORY_REPO.contains(',')) {
						String[] repos = params.ARTIFACTORY_REPO.split(",")
						// Assumption: ARTIFACTORY_REPO=X,Y (X=to upload results, Y=to download ri)
						repoForRi = repos[1].trim()
						if (!env.SPEC.startsWith('aix') && !env.SPEC.startsWith('zos')) {
							riURL = "${artifactoryUrl}/${repoForRi}/Latest/${PLATFORM}/${JDK_VERSION}"
						}
					}
					CUSTOMIZED_SDK_URL_OPTION = "-c '${params.CUSTOMIZED_SDK_URL} ${riURL}'"
				}
			} else {
				error("SDK_RESOURCE: ${params.SDK_RESOURCE} and CUSTOMIZED_SDK_URL: ${params.CUSTOMIZED_SDK_URL} combo is not supported!")
			}
		} else {
			if (params.SDK_RESOURCE == 'customized') {
				error("SDK_RESOURCE: ${params.SDK_RESOURCE}, please provide CUSTOMIZED_SDK_URL")
			} else {
				CUSTOMIZED_SDK_URL_OPTION = ""
			}
		}

		if (SDK_RESOURCE == 'upstream') {
			timeout(time: 1, unit: 'HOURS') {
				dir('jdkbinary') {
					step([$class: 'CopyArtifact',
							fingerprintArtifacts: true,
							flatten: true,
							filter: "**/*.tar.gz,**/*.tgz,**/*.zip,**/*.jar,**/*.Z,**/*sbom*.json",
							projectName: "${params.UPSTREAM_JOB_NAME}",
							selector: [$class: 'SpecificBuildSelector', buildNumber: "${params.UPSTREAM_JOB_NUMBER}"]])
				}
			}
		}
		OPENJ9_REPO_OPTION = ""
		OPENJ9_BRANCH_OPTION = ""
		TKG_REPO_OPTION = ""
		TKG_BRANCH_OPTION = ""
		OPENJ9_SHA_OPTION = ""
		CLONE_OPENJ9_OPTION = (params.CLONE_OPENJ9) ? "--clone_openj9 ${params.CLONE_OPENJ9}" : ""
		// if CLONE_OPENJ9 parameter is not set, only clone openj9 if we are running functional tests
		if (CLONE_OPENJ9_OPTION == "") {
			if (env.BUILD_LIST.contains('functional')) {
				CLONE_OPENJ9_OPTION = "--clone_openj9 true"
				// If USE_TESTENV_PROPERTIES = false, set Openj9 repo and brnach.
				// Otherwise, testenv.properties will be used.
				// And the Openj9 repo and brnach values will be set in get.sh
				if(!params.USE_TESTENV_PROPERTIES) {
					OPENJ9_REPO_OPTION = "--openj9_repo ${OPENJ9_REPO}"
					OPENJ9_BRANCH_OPTION = "--openj9_branch ${OPENJ9_BRANCH}"
					OPENJ9_SHA_OPTION = (params.OPENJ9_SHA) ? "--openj9_sha ${params.OPENJ9_SHA}" : ""
				}
			} else {
				CLONE_OPENJ9_OPTION = "--clone_openj9 false"
			}
		}
		JDK_VERSION_OPTION = env.JDK_VERSION ? "-j ${env.JDK_VERSION}" : ""
		JDK_IMPL_OPTION = env.JDK_IMPL ? "-i ${env.JDK_IMPL}" : ""

		// system test repository exports to be used by system/common.xml
		if(!params.USE_TESTENV_PROPERTIES){
			String[] adoptSystemTest = getGitRepoBranch(params.ADOPTOPENJDK_SYSTEMTEST_OWNER_BRANCH, "adoptium:master", "aqa-systemtest")
			env.ADOPTOPENJDK_SYSTEMTEST_REPO = adoptSystemTest[0]
			env.ADOPTOPENJDK_SYSTEMTEST_BRANCH = adoptSystemTest[1]

			String[] openj9SystemTest = getGitRepoBranch(params.OPENJ9_SYSTEMTEST_OWNER_BRANCH, "eclipse:master", "openj9-systemtest")
			env.OPENJ9_SYSTEMTEST_REPO = openj9SystemTest[0]
			env.OPENJ9_SYSTEMTEST_BRANCH = openj9SystemTest[1]

			String[] stf = getGitRepoBranch(params.STF_OWNER_BRANCH, "adoptium:master", "STF")
			env.STF_REPO = stf[0]
			env.STF_BRANCH = stf[1]

			TKG_REPO_OPTION = "--tkg_repo ${TKG_REPO}"
			TKG_BRANCH_OPTION = "--tkg_branch ${TKG_BRANCH}"
		}
		// vendor test
		// expect VENDOR_TEST_* to be comma separated string parameters
		VENDOR_TEST_REPOS = (params.VENDOR_TEST_REPOS) ? "--vendor_repos \"${params.VENDOR_TEST_REPOS}\"" : ""
		VENDOR_TEST_BRANCHES = (params.VENDOR_TEST_BRANCHES) ? "--vendor_branches \"${params.VENDOR_TEST_BRANCHES}\"" : ""
		VENDOR_TEST_DIRS = (params.VENDOR_TEST_DIRS) ? "--vendor_dirs \"${params.VENDOR_TEST_DIRS}\"" : ""
		VENDOR_TEST_SHAS = (params.VENDOR_TEST_SHAS) ? "--vendor_shas \"${params.VENDOR_TEST_SHAS}\"" : ""
		env.IS_SVT_TESTREPO = (params.VENDOR_TEST_REPOS && params.VENDOR_TEST_REPOS.contains('SVTTestRepo')) ? true : false
		echo "IS_SVT_TESTREPO is set to ${env.IS_SVT_TESTREPO}"

		// handle three cases (true/false/null) in params.TEST_IMAGES_REQUIRED and params.DEBUG_IMAGES_REQUIRED
		// Only set image required to false if params is set to false. In get.sh, the default value is true
		TEST_IMAGES_REQUIRED = (params.TEST_IMAGES_REQUIRED == false) ? "--test_images_required false" : ""
		DEBUG_IMAGES_REQUIRED = (params.DEBUG_IMAGES_REQUIRED == false) ? "--debug_images_required false" : ""
		CODE_COVERAGE_OPTION = params.CODE_COVERAGE ? "--code_coverage true" : ""
		ADDITIONAL_ARTIFACTS_REQUIRED_OPTION = (params.ADDITIONAL_ARTIFACTS_REQUIRED) ? "--additional_artifacts_required ${params.ADDITIONAL_ARTIFACTS_REQUIRED}" : ""

		CURL_OPTS = (params.CURL_OPTS) ? "--curl_opts \"${params.CURL_OPTS}\"" : ""
		GET_SH_CMD = "./get.sh -s `pwd`/.. -p $PLATFORM -r ${SDK_RESOURCE} ${JDK_VERSION_OPTION} ${JDK_IMPL_OPTION} ${CUSTOMIZED_SDK_URL_OPTION} ${CLONE_OPENJ9_OPTION} ${OPENJ9_REPO_OPTION} ${OPENJ9_BRANCH_OPTION} ${OPENJ9_SHA_OPTION} ${TKG_REPO_OPTION} ${TKG_BRANCH_OPTION} ${VENDOR_TEST_REPOS} ${VENDOR_TEST_BRANCHES} ${VENDOR_TEST_DIRS} ${VENDOR_TEST_SHAS} ${TEST_IMAGES_REQUIRED} ${DEBUG_IMAGES_REQUIRED} ${CODE_COVERAGE_OPTION} ${CURL_OPTS} ${ADDITIONAL_ARTIFACTS_REQUIRED_OPTION}"
		RESOLVED_MAKE = "if [ `uname` = AIX ] || [ `uname` = SunOS ] || [ `uname` = *BSD ]; then MAKE=gmake; else MAKE=make; fi"
		dir( WORKSPACE) {
			// use sshagent with Jenkins credentials ID for all platforms except zOS
			// on zOS use the user's ssh key
			if (!env.SPEC.startsWith('zos')) {
				get_sources_with_authentication()
			} else {
				get_sources()
			}
			getJobProperties()
		}
	}
}

def setup_jck_interactives() {
	def targetDir = "${env.WORKSPACE}/../../jck_run/jdk${JDK_VERSION}/jdk"
	if (PLATFORM.contains("windows")) {
		targetDir = "c:/Users/jenkins/jck_run/jdk${JDK_VERSION}/jdk"
	}
	def tarBall = CUSTOMIZED_SDK_URL.tokenize('/').last()
	echo "tarBall is ${tarBall}"
	def jckRunDirExists = sh(script: """
		if [ -d "${targetDir}" ]; then
			echo true
		else
			echo false
		fi
		""", returnStdout: true).toBoolean()

	if (jckRunDirExists) {
		def jdkDir = ""
		if (PLATFORM.contains("windows")) {
			jdkDir = sh(script: "unzip -l `pwd`/jdkbinary/${tarBall} | head -n 4 | tail -n 1 | xargs -n 1 echo | tail -n 1", returnStdout: true).trim().replaceFirst(".\$","")
			if (PLATFORM.contains("x86-32_windows")) {
				jdkDir = "${jdkDir}_32"
			} else if (PLATFORM.contains("x86-64_windows")) {
				jdkDir = "${jdkDir}_64"
			}
		} else {
			jdkDir = sh(script: "tar -tf `pwd`/jdkbinary/${tarBall} | head -1", returnStdout: true).trim().replaceFirst(".\$","")
		}
		def jckRunDir = "${targetDir}/${jdkDir}"
		def jckRunJDKExists = sh(script: """
		if [ -d "${jckRunDir}" ]; then
			echo true
		else
			echo false
		fi
		""", returnStdout: true).toBoolean()

		if (!jckRunJDKExists) {
			sh returnStatus: true, script: """
				cd ${targetDir}
				mkdir ${jdkDir}
				cd ${jdkDir}
				cp -r ${TEST_JDK_HOME}/* .
				chgrp -R jck ${targetDir}/${jdkDir}
				chmod -R 775 ${targetDir}/${jdkDir}
				"""
		}
	}
}

def getJobProperties() {
	def jobProperties = "./aqa-tests/job.properties"
	if (fileExists("${jobProperties}")) {
		echo "readProperties file: ${jobProperties}"
		def properties = readProperties file: "${jobProperties}"
		if (properties.TEST_JDK_HOME) {
			env.TEST_JDK_HOME = properties.TEST_JDK_HOME
			echo "Reset TEST_JDK_HOME to ${TEST_JDK_HOME}"
		}
	}
}

def get_sources_with_authentication() {
	sshagent(credentials:["${params.USER_CREDENTIALS_ID}"], ignoreMissing: true) {
		get_sources()
	}
}

def get_sources() {
	dir('aqa-tests') {
		if (params.CUSTOMIZED_SDK_URL_CREDENTIAL_ID) {
			// USERNAME and PASSWORD reference with a withCredentials block will not be visible within job output
			withCredentials([usernamePassword(credentialsId: "${params.CUSTOMIZED_SDK_URL_CREDENTIAL_ID}", usernameVariable: 'USERNAME', passwordVariable: 'PASSWORD')]) {
				sh "$GET_SH_CMD"
			}
		} else {
			sh "$GET_SH_CMD"
		}
	}
	if (params.SETUP_JCK_RUN && env.BUILD_LIST.contains('jck') && SDK_RESOURCE.contains('customized')) {
		setup_jck_interactives()
	}
}
def makeCompileTest(){
	String makeTestCmd = "bash ./compile.sh"
	//unset LD_LIBRARY_PATH workaround for issue https://github.com/adoptium/infrastructure/issues/2934
	if (JDK_IMPL == 'hotspot' && PLATFORM.contains('alpine-linux')) {
		makeTestCmd = "unset LD_LIBRARY_PATH; $makeTestCmd"
	}
	dir('aqa-tests') {
		if (!env.SPEC.startsWith('zos')) {
			sshagent (credentials: ["$params.SSH_AGENT_CREDENTIAL"], ignoreMissing: true) {
				sh "$makeTestCmd";
			}
		} else {
			sh "$makeTestCmd";
		}
	}
}

def buildTest() {
	stage('Build') {
		echo 'Building tests...'

		if ( params.PERF_CREDENTIALS_ID ) {
			withCredentials([usernamePassword(credentialsId: "$params.PERF_CREDENTIALS_ID",
					passwordVariable: "PASSWORD_VAR", usernameVariable: "USERNAME_VAR")]) {
				env.PERF_USERNAME = USERNAME_VAR
				env.PERF_PASSWORD = PASSWORD_VAR
			}
		}

		if (params.UPSTREAM_TEST_JOB_NAME && params.UPSTREAM_TEST_JOB_NUMBER) {
			try {
				timeout(time: 1, unit: 'HOURS') {
					copyArtifacts fingerprintArtifacts: true, projectName: params.UPSTREAM_TEST_JOB_NAME, selector: specific(params.UPSTREAM_TEST_JOB_NUMBER), filter: "**/parallelList.mk", target: './aqa-tests/TKG/'
				}
			} catch (Exception e) {
				echo 'Exception: ' + e.toString()
				echo "Cannot run copyArtifacts from ${params.UPSTREAM_TEST_JOB_NAME} ${params.UPSTREAM_TEST_JOB_NUMBER}. Skipping copyArtifacts..."
			}
		}

		try {
				// check pre-stage test libs on the machine
				// check for each lib. If lib does not exist, donwload it.
				// If lib exists, SHA will be checked. Re-download if SHA does not match.
				timeout(time: 20, unit: 'MINUTES') {
					def customUrl = getCustomUrl()
					if (PLATFORM.contains("windows")) {
						env.LIB_DIR = env.LIB_DIR.replaceAll("\\\\", "/")
						env.SYSTEM_LIB_DIR = env.SYSTEM_LIB_DIR.replaceAll("\\\\", "/")
					}
					if (env.BUILD_LIST == 'system') {
						env.LIB_DIR = env.SYSTEM_LIB_DIR
					}
					sh "perl ./aqa-tests/TKG/scripts/getDependencies.pl -path ${env.LIB_DIR} -task default -customUrl ${customUrl}"
				}
			} catch (Exception e) {
					echo 'Exception: ' + e.toString()
					echo "Cannot pre-stage test libs from ${env.LIB_DIR} on the machine. Skipping..."
			}

		if (BUILD_LIST.contains("external")){
			try {
				timeout(time: 60, unit: 'MINUTES') {
					copyArtifacts fingerprintArtifacts: true, projectName: "UploadFileOnJenkins", selector: specific("2"), target: 'aqa-tests/external/criu/'
					copyArtifacts fingerprintArtifacts: true, projectName: "UploadFileOnJenkins", selector: specific("3"), target: 'aqa-tests/external/criu/'
				}
			} catch (Exception e) {
				echo 'Exception: ' + e.toString()
				echo 'Cannot run copyArtifacts from UploadFileOnJenkins. Skipping copyArtifacts...'
			}
		}

		if (fileExists('jdkbinary/openjdk-test-image')) {
			env.TESTIMAGE_PATH = "$WORKSPACE/jdkbinary/openjdk-test-image"
		}

		if (fileExists('jdkbinary/openjdk-test-image/openj9')) {
			env.NATIVE_TEST_LIBS = "$WORKSPACE/jdkbinary/openjdk-test-image/openj9"
		}

		if (!params.DYNAMIC_COMPILE) {
			if(params.CUSTOMIZED_SDK_URL_CREDENTIAL_ID) {
				withCredentials([usernamePassword(credentialsId: "${params.CUSTOMIZED_SDK_URL_CREDENTIAL_ID}",
						usernameVariable: 'USERNAME', passwordVariable: 'PASSWORD')]) {
					makeCompileTest()
				}
			} else {
				makeCompileTest()
			}
		}

		if (params.CODE_COVERAGE) {
			echo "Clean gcda files before generating new Code Coverage info"
			sh "find ${WORKSPACE}/jdkbinary/j2sdk-image -name '*.gcda' -type f -delete"
		}
	}
}

def runTest( ) {
	stage('Test') {
		echo 'Running tests...'
		def CUSTOM_OPTION = ''

		TARGET = "${params.TARGET}";
		if (TARGET.contains('custom') && CUSTOM_TARGET!='') {
			if (TARGET == 'system_custom') {
				env.SYSTEM_CUSTOM_TARGET=CUSTOM_TARGET
			} else {
				// remove suffix, then set CUSTOM_OPTION (i.e., jdk_custom_0 will become jdk_custom)
				def removeDisabled = TARGET.replaceAll("disabled.", "")
				def removeSuffix = removeDisabled.replaceAll(/_\d+$/, "")
				CUSTOM_OPTION = "${removeSuffix.toUpperCase()}_TARGET='${CUSTOM_TARGET}'"
			}
		}
		if (!TARGET.startsWith('-f')) {
			TARGET="_${params.TARGET}"
		} else if (TARGET.contains('-f parallelList.mk') && SPEC.startsWith('zos')) {
			def parallelList = "aqa-tests/TKG/parallelList.mk"
			if (fileExists("${parallelList}")) {
				echo 'Converting parallelList.mk file from ascii to ebcdic...'
				sh "iconv -f iso8859-1 -t ibm-1047 ${parallelList} > ${parallelList}.ebcdic; rm ${parallelList}; mv ${parallelList}.ebcdic ${parallelList}"
			}
		}

		RUNTEST_CMD = "${TARGET} ${CUSTOM_OPTION}"
		if (env.BUILD_LIST.contains('jck') || env.BUILD_LIST.contains('openjdk') || env.BUILD_LIST.contains('functional')) {
			if (env.SPEC.startsWith('aix')) {
				sh "/usr/bin/X11/X -force -vfb -x abx -x dbe -x GLX -secIP 000 :0 &"
				env.DISPLAY = "unix:0"
				echo "env.DISPLAY is ${env.DISPLAY}"

			} else if (env.SPEC.startsWith('sunos')) {
				sh "/usr/X11/bin/Xvfb :2 -screen 0 1024x768x24 &"
				env.DISPLAY = ":2"
				echo "env.DISPLAY is ${env.DISPLAY}"
			}
		}
		for (int i = 1; i <= ITERATIONS; i++) {
			echo "ITERATION: ${i}/${ITERATIONS}"
			if (env.SPEC.contains('linux') && !(LABEL.contains('ci.agent.dynamic') && CLOUD_PROVIDER == 'azure') && (BUILD_LIST != "external")) {
				// Add an additional 10 second timeout due to issue: https://github.com/adoptium/temurin-build/issues/2368#issuecomment-756683888
				wrap([$class: 'Xvfb', autoDisplayName: true, timeout:20]) {
					def DISPLAY = sh (
							script: 'ps -f | grep \'[X]vfb\' | awk \'{print \$9}\'',
							returnStdout: true
					).trim()
					env.DISPLAY = "${DISPLAY}"
					echo "env.DISPLAY is ${env.DISPLAY}"
					makeTest("${RUNTEST_CMD}")
				}
			} else if (BUILD_LIST.contains('external')) {
				sshagent (credentials: ["$params.SSH_AGENT_CREDENTIAL"], ignoreMissing: true) {
					makeTest("${RUNTEST_CMD}")
				}
			}
			else {
				makeTest("${RUNTEST_CMD}")
			}
		}

		if (params.CODE_COVERAGE) {
			echo 'Generating Code Coverage Reports...'
			dir("$WORKSPACE/jdkbinary/j2sdk-image") {
				// Current lcov generates "Cannot open source file" info, but does not affect results, since Build and Test paths difference are corrected after summary.
				sh "lcov --capture --quiet --directory . --output-file codeCoverageInfoOrigin.info --rc geninfo_adjust_src_path='/home/jenkins/workspace/ => ${WORKSPACE}/jdkbinary/j2sdk-image/jenkins/workspace/'"
				sh "lcov --quiet --output-file codeCoverageInfoFinal.info --remove codeCoverageInfoOrigin.info '/usr/include/*' '/usr/local/*' '/home/*/attrlookup.gperf'"
				sh "genhtml --quiet codeCoverageInfoFinal.info --output-directory code_coverage_report"
			}
		}

		def resultSum = [:]
		def matcher = manager.getLogMatcher(".*(TOTAL: \\d+)\\s*(EXECUTED: \\d+)\\s*(PASSED: \\d+)\\s*(FAILED: \\d+)\\s*(DISABLED: \\d+)?\\s*(SKIPPED: \\d+)\\s*\$")
		if (matcher?.matches()) {
			for (int i = 1; i <= matcher.groupCount(); i++) {
				if (matcher.group(i) != null) {
					def matchVals = matcher.group(i).split(": ")
					resultSum[matchVals[0]] = matchVals[1] as int
				}
			}
			checkTestResults(resultSum)
		} else {
			currentBuild.result = 'FAILURE'
			echo 'Could not find test result, set build result to FAILURE.'
			def summary = manager.createSummary("error.svg")
			summary.appendText("TEST BUILD FAILURE!", false)
		}
	}
}

def checkTestResults(results) {
	if (results.isEmpty()) {
		return
	}

	def summary = null

	if (results["TOTAL"] == 0) {
		currentBuild.result = 'FAILURE'
		echo 'No test ran, set build result to FAILURE.'
		summary = manager.createSummary("folder-delete.svg")
		summary.appendText("NO TEST FOUND!", false)
		return
	}

	if (results["FAILED"] != 0) {
		currentBuild.result = 'UNSTABLE'
		echo 'There were test failures, set build result to UNSTABLE.'
		summary = manager.createSummary("warning.svg")
	} else {
		summary = manager.createSummary("accept.svg")
	}

	summary.appendText("TEST TARGETS SUMMARY:<ul>", false)
	results.each {
		summary.appendText("<li><b>$it.key</b> : $it.value</li>", false)
	}
	summary.appendText("</ul>", false)
}

def post(output_name) {
	stage('Post') {
		if (env.DISPLAY != null) {
			env.DISPLAY = ""
		}
		if (output_name.contains(',')) {
			output_name = "specifiedTarget"
		}
		else {
			output_name = output_name.replace("/","_")
		}
		def tar_cmd = "tar -cf"
		// Use pigz if we can as it is faster - 2> hides fallback message
		def tar_cmd_suffix = "| (pigz -9 2>/dev/null || gzip -9)"
		def suffix = ".tar.gz"
		def pax_opt = ""
		if (SPEC.startsWith('zos')) {
			echo 'Converting tap file from ebcdic to ascii...'
			sh 'cd ./aqa-tests/TKG'
			def tapFiles = findFiles(glob: "**/*.tap")
			for (String tapFile : tapFiles) {
				sh "iconv -f ibm-1047 -t iso8859-1 ${tapFile} > ${tapFile}.ascii; rm ${tapFile}; mv ${tapFile}.ascii ${tapFile}"
			}

			tar_cmd = "pax -wf"
			suffix = ".pax.Z"
			pax_opt = "-x pax"
			tar_cmd_suffix = ""
		}

		step([$class: "TapPublisher", testResults: "aqa-tests/TKG/**/*.tap", outputTapToConsole: false, failIfNoResults: true])

		//call the archive function for each file
		archiveFile("aqa-tests/testenv/testenv.properties", true)
		archiveFile("aqa-tests/TKG/**/*.tap", true)
		archiveAQAvitFiles()

		if (env.BUILD_LIST.startsWith('jck')) {
			xunit (
					tools: [Custom(customXSL: "$WORKSPACE/aqa-tests/jck/xUnit.xsl",
							deleteOutputFiles: true,
							failIfNotNew: false,
							pattern: "**/TKG/output_*/**/report.xml",
							skipNoTestFiles: true,
							stopProcessingIfError: true)]
			)
		}

		//for performance test, archive regardless the build result
		if (env.BUILD_LIST.startsWith('perf')) {
			def benchmark_output_tar_name = "benchmark_test_output${suffix}"
			sh "${tar_cmd} ${benchmark_output_tar_name} ${pax_opt} ./aqa-tests/TKG/output_*"
			if (!params.ARTIFACTORY_SERVER) {
				echo "ARTIFACTORY_SERVER is not set. Saving artifacts on jenkins."
				archiveArtifacts artifacts: benchmark_output_tar_name, fingerprint: true, allowEmptyArchive: true
			} else {
				def pattern = "${env.WORKSPACE}/*_output.*"
				uploadToArtifactory(pattern)
			}
		} else if ((currentBuild.result == 'UNSTABLE' || currentBuild.result == 'FAILURE' || currentBuild.result == 'ABORTED') || params.ARCHIVE_TEST_RESULTS) {
			def test_output_tar_name = "${output_name}_test_output${suffix}"
			if (tar_cmd.startsWith('tar')) {
				sh "${tar_cmd} - ${pax_opt} ./aqa-tests/TKG/output_* ${tar_cmd_suffix} > ${test_output_tar_name}"
			} else {
				sh "${tar_cmd} ${test_output_tar_name} ${pax_opt} ./aqa-tests/TKG/output_* ${tar_cmd_suffix}"
			}

			// TODO: archiveFile() should be used
			if (!params.ARTIFACTORY_SERVER) {
				echo "ARTIFACTORY_SERVER is not set. Saving artifacts on jenkins."
				archiveArtifacts artifacts: test_output_tar_name, fingerprint: true, allowEmptyArchive: true
			} else {
				def pattern = "${env.WORKSPACE}/*_output.*"
				uploadToArtifactory(pattern)
			}

			if (env.BUILD_LIST.startsWith('external')) {
				archiveFile("**/Dockerfile.*", true)
			}

			if (params.ARCHIVE_TEST_RESULTS && !env.JDK_VERSION.contains(',') && env.BUILD_LIST.contains('jck')) {
				def natives_tar_name = "natives${suffix}"
				def natives_dir = "${WORKSPACE}/../../jck_root/JCK${env.JDK_VERSION}-unzipped/natives"
				if (tar_cmd.startsWith('tar')) {
					sh "${tar_cmd} - ${pax_opt} ${natives_dir} ${tar_cmd_suffix} > ${natives_tar_name}"
				} else {
					sh "${tar_cmd} ${natives_tar_name} ${pax_opt} ${natives_dir} ${tar_cmd_suffix}"
				}
				archiveFile(natives_tar_name, false)
			}

		}

		if (params.CODE_COVERAGE) {
			echo "Archive Code Coverage Report"
			def code_coverage_report_tar_name = "${output_name}_code_coverage_report${suffix}"
			dir("${WORKSPACE}/jdkbinary/j2sdk-image") {
				if (tar_cmd.startsWith('tar')) {
					sh "${tar_cmd} - ${pax_opt} codeCoverageInfoFinal.info code_coverage_report ${tar_cmd_suffix} > ${code_coverage_report_tar_name}"
				} else {
					sh "${tar_cmd} ${code_coverage_report_tar_name} ${pax_opt} codeCoverageInfoFinal.info code_coverage_report ${tar_cmd_suffix}"
				}
			}
			if (!params.ARTIFACTORY_SERVER) {
				echo "ARTIFACTORY_SERVER is not set. Saving artifacts on jenkins."
				archiveArtifacts artifacts: code_coverage_report_tar_name, fingerprint: true, allowEmptyArchive: true
			} else {
				def pattern = "${env.WORKSPACE}/*_code_coverage_report.*"
				uploadToArtifactory(pattern)
			}
		}

		addFailedTestsGrinderLink()

		try {
			junit allowEmptyResults: true, keepLongStdio: true, testResults: '**/work/**/*.jtr.xml, **/result/**/*.jtr.xml, **/junitreports/**/*.xml, **/external_test_reports/**/*.xml'
		} catch (Exception e) {
			echo "Caught exception: ${e.message}"
		}
	}
}

def testBuild() {
	TIME_LIMIT = params.TIME_LIMIT ? params.TIME_LIMIT.toInteger() : 10
	timeout(time: TIME_LIMIT, unit: 'HOURS') {
		try {
			addJobDescription()
			setup()
			addGrinderLink()
			// prepare environment and compile test projects
			if ((params.PARALLEL == "NodesByIterations" && NUM_MACHINES > 1)
				|| (params.PARALLEL == "Dynamic" && (NUM_MACHINES > 1 || (params.TEST_TIME && !params.NUM_MACHINES)))) {
				if (setupParallelEnv() == 1) {
					// No need to run tests in parallel
					testExecution()
				}
			} else {
				testExecution()
			}
		} finally {
			// Terminate any left over test job processes
			terminateTestProcesses()

			if (!params.KEEP_WORKSPACE) {
				forceCleanWS()
				// clean up remaining core files
				if (PLATFORM.contains("mac")) {
					sh "find /cores -name '*core*' -print 2>/dev/null -exec rm -f {} \\; || true"
				} else if (PLATFORM.contains("windows")) {
					sh "find /cygdrive/c/temp -name '*core*' -print 2>/dev/null -exec rm -f {} \\; || true"
				} else {
					sh "find /tmp -name '*core*' -print 2>/dev/null -exec rm -f {} \\; || true"
				}
			}
		}
	}
}

def testExecution() {
	try {
		//ToDo: temporary workaround for jck test parallel runs
		// until build.xml is added into each subfolder
		if( env.BUILD_LIST.startsWith('jck/')) {
			def temp = env.BUILD_LIST
			env.BUILD_LIST = "jck"
			buildTest()
			env.BUILD_LIST = temp
		} else {
			buildTest()
		}
		if(env.BUILD_LIST.startsWith('jck') && !env.SPEC.startsWith('zos')) {
			sshagent(credentials:["${params.JENKINS_KEY}"], ignoreMissing: true) {
				runTest()
			}
		} else {
			runTest()
		}
	} finally {
		post("${env.BUILD_LIST}")
	}
}

def terminateTestProcesses() {
	echo "PROCESSCATCH: Terminating any hung/left over test processes:"

	def statusCode=sh(script:"aqa-tests/terminateTestProcesses.sh ${env.USER} 2>&1", returnStatus:true)
	if (statusCode != 0) {
			echo "rc = ${statusCode}, Unable to terminate all processes."
	}
}

def getJDKImpl(jvm_version) {
	def jdk_impl = 'hotspot'
	if (jvm_version.contains('openj9')) {
		jdk_impl = 'openj9'
	} else if (JVM_VERSION.contains('sap')) {
		jdk_impl = 'sap'
	}
	return jdk_impl
}

def addJobDescription() {
	if (params.PERSONAL_BUILD) {
		// update build name if personal build
		wrap([$class: 'BuildUser']) {
			currentBuild.displayName = "#${BUILD_NUMBER} - ${BUILD_USER_EMAIL}"
		}
	}
	def description = (currentBuild.description) ? currentBuild.description + "<br>" : ""
	currentBuild.description = description \
		+ "TARGET: ${params.TARGET}<br/>" \
		+ "LABEL: <a href=${JENKINS_URL}label/${LABEL}>${LABEL}</a><br/>" \
		+ "<a href=${JENKINS_URL}computer/${NODE_NAME}>${NODE_NAME}</a>"
}

def getJenkinsDomain() {
	String regex = env.JENKINS_URL
	def m = regex =~ /:\/\/(.*)\/?/
	def match = m[0][1]
	def domainName = "undefined"
	if (match) {
		domainName = match
	}
	return domainName
}

def getCustomUrl() {
	def jenkinsDomain = getJenkinsDomain()
	if (jenkinsDomain.contains("hyc-runtimes")) {
		jenkinsDomain = "openj9-jenkins.osuosl.org"
	} else if (jenkinsDomain.contains("temurin-compliance")) {
                jenkinsDomain = "ci.adoptium.net"
        }

	def customUrl = "https://${jenkinsDomain}/job/test.getDependency/lastSuccessfulBuild/artifact/"
	echo "Custom URL: ${customUrl}"
	return customUrl
}

def archiveAQAvitFiles() {
	if (params.USE_TESTENV_PROPERTIES && !JOB_NAME.contains("_testList_")) {
		if (params.ARTIFACTORY_SERVER) {
			def currentDate = new Date()
			def currentDateTime = currentDate.format("yyyyMMddHHmmss", TimeZone.getTimeZone('UTC'))
			def uploadDir = "AQAvit/${JDK_IMPL}/${env.ADOPTOPENJDK_BRANCH}/${JDK_VERSION}/${PLATFORM}/${currentDateTime}"
			uploadToArtifactory("${env.WORKSPACE}/**/*.tap", uploadDir)
		}
	}
}

// If forceStoreOnJenkins set to true, archive on Jenkins.
// If forceStoreOnJenkins set to false, archive on Artifactory if ARTIFACTORY_SERVER is provided. Otherwise, archive on Jenkins
def archiveFile(filename, forceStoreOnJenkins) {
	if (!params.ARTIFACTORY_SERVER || forceStoreOnJenkins) {
		echo "Saving ${filename} file on jenkins."
		archiveArtifacts artifacts: filename, fingerprint: true, allowEmptyArchive: true
	}
	if (params.ARTIFACTORY_SERVER) {
		def pattern = "${env.WORKSPACE}/${filename}"
		uploadToArtifactory(pattern)
	}
}

def uploadToArtifactory(pattern, artifactoryUploadDir="") {
	if (params.ARTIFACTORY_SERVER) {
		def server = Artifactory.server params.ARTIFACTORY_SERVER
		def artifactoryRepo = params.ARTIFACTORY_REPO ? params.ARTIFACTORY_REPO : "sys-rt-generic-local"

		if (artifactoryRepo.contains(',')) {
			String[] repos = artifactoryRepo.split(",")
			artifactoryRepo = repos[0].trim()
		}

		def artifactoryRoorDir = params.ARTIFACTORY_ROOT_DIR ? params.ARTIFACTORY_ROOT_DIR : getJenkinsDomain()
		if (artifactoryRoorDir.endsWith("/")) {
			artifactoryRoorDir = artifactoryRoorDir.substring(0, artifactoryRoorDir.length() - 1);
		}
		def fullUploadPath = "${artifactoryRepo}/${artifactoryRoorDir}/${JOB_NAME}/${BUILD_ID}/"
		if (artifactoryUploadDir) {
			fullUploadPath = "${artifactoryRepo}/${artifactoryRoorDir}/${artifactoryUploadDir}/"
		}

		def uploadSpec = """{
			"files":[
					{
						"pattern": "${pattern}",
						"target": "${fullUploadPath}"
					}
				]
			}"""

		def buildInfo = Artifactory.newBuildInfo()

		if (artifactoryUploadDir && artifactoryUploadDir.contains("AQAvit")) {
			buildInfo.name = "sys-rt/AQAvit_" + buildInfo.name
		} else {
			buildInfo.name = "sys-rt/" + buildInfo.name
			def numArtifacts = params.ARTIFACTORY_NUM_ARTIFACTS ?: -1
			def numDays = 20
			if (params.ARTIFACTORY_NUM_DAYS) {
				numDays = params.ARTIFACTORY_NUM_DAYS
			} else {
				if (ARTIFACTORY_SERVER.contains("ci-eclipse-openj9")) {
					if (JOB_NAME.contains("Grinder")) {
						numDays = 7
					} else {
						numDays = 25
					}
				} else {
					if (JOB_NAME.contains("Grinder")) {
						numDays = 20
					} else {
						numDays = 45
					}
				}
			}
			buildInfo.retention maxBuilds: numArtifacts, maxDays: numDays, deleteBuildArtifacts: true
		}
		server.upload spec: uploadSpec, buildInfo: buildInfo
		server.publishBuildInfo buildInfo

		def artifactoryUrl = server.getUrl()
		def uploadUrl = "${artifactoryUrl}/${fullUploadPath}"
		if (!currentBuild.description.contains(uploadUrl)) {
			if (uploadUrl.contains("AQAvit")) {
				echo "AQAvit files artifactory URL:'${uploadUrl}'"
				currentBuild.description += "<br><a href=${uploadUrl}>AQAvit Artifacts</a>"
			} else {
				echo "Test output artifactory URL:'${uploadUrl}'"
				currentBuild.description += "<br><a href=${uploadUrl}>Artifacts</a>"
			}
		}
	} else {
		echo "ARTIFACTORY_SERVER is not set. Artifacts are not uploaded onto artifactory server."
	}
}

def addGrinderLink() {
	String url = "${HUDSON_URL}job/Grinder/parambuild/?"
	int i = 1;
	def labelValue = ""
	def targetValue = ""
	def customTargetKeyValue = ""
	def urlParams = params.findAll {
		// Exclude separator and help text parameters from url
		!(it.key.endsWith('_PARAMS') || it.key.endsWith('_HELP_TEXT'))
	}
	urlParams.each { key, value ->
		value = URLEncoder.encode(value.toString(), "UTF-8")
		if (key == "LABEL") {
			labelValue = "LABEL=${value}"
		}
		if (key == "TARGET") {
			targetValue = "TARGET=${value}"
		}
		if (key == "CUSTOM_TARGET") {
			customTargetKeyValue = "CUSTOM_TARGET=${value}"
		}
		// Always set RERUN_ITERATIONS to 0 for Grinder link
		if (key == "RERUN_ITERATIONS") {
			value = "0"
		}
		// Always set LightWeightCheckout to false for Grinder link
		if (key == "LIGHT_WEIGHT_CHECKOUT") {
			value = "false"
		}
		// Always set Parallel to None for Grinder link
		if (key == "PARALLEL") {
			value = "None"
		}

		url += "${key}=${value}"
		if (i != urlParams.size()) {
			url += "&amp;"
		}
		i++;
	}

	env.RERUN_LINK = url
	env.FAILED_TEST_TARGET = targetValue
	env.CUSTOM_TARGET_KEY_VALUE = customTargetKeyValue

	currentBuild.description += "<br><a href=\"https://github.com/adoptium/aqa-tests/wiki/How-to-Run-a-Grinder-Build-on-Jenkins\">Grinder Wiki</a>"
	echo "Rerun in Grinder: ${url}"
	currentBuild.description += "<br><a href=${url}>Rerun in Grinder</a> Change TARGET to run only the failed test targets."
	def sameMachineUrl = url.replace(labelValue,"LABEL=${NODE_NAME}")
	echo "Rerun in Grinder on same machine: ${sameMachineUrl}"
	currentBuild.description += "<br><a href=${sameMachineUrl}>Rerun in Grinder on same machine</a> Change TARGET to run only the failed test targets. For dynamic vm agents as they are created at runtime and quickly recycled, it may not be possible to rerun on the same agent."
}

def addFailedTestsGrinderLink(paths=""){
	if (currentBuild.result == 'UNSTABLE' || currentBuild.result == 'FAILURE' || currentBuild.result == 'ABORTED') {
		def failedTestList = ""
		def jdkFailedTestCaseList = ""
		def hotspotFailedTestCaseList = ""
		def jckRuntimeFailedTestCaseList = ""
		def jckCompilerFailedTestCaseList = ""
		def jckDevtoolsFailedTestCaseList = ""
		List<String> buildPaths = paths.split(',')
		for (def buildPath: buildPaths) {
			def tapFiles = findFiles(glob: "${buildPath}**/*.tap")
			for (def tapFile: tapFiles) {
				echo "Tap file found: ${tapFile}..."
				def file = readFile(file: "${tapFile}")
				TapConsumer tapConsumer = TapConsumerFactory.makeTap13YamlConsumer()
				TestSet testSet = tapConsumer.load(file)
				for (int i = 1; i <= testSet.getNumberOfTestResults(); i++) {
					if (!testSet.getTestResult(i).getStatus().toString().equals("ok")) {
						def failedtest = testSet.getTestResult(i).getDescription().trim().substring(2)
						failedTestList += "${failedtest},"
						if (env.BUILD_LIST.contains('openjdk') || env.BUILD_LIST.contains('jck')) {
							def failedTestCasesInfo = testSet.getTestResult(i).getDiagnostic().get("output").toString()
							if (failedTestCasesInfo.contains("Failed test cases:") && failedTestCasesInfo.contains("Test results:")) {
								failedTestCasesInfo = failedTestCasesInfo.substring(failedTestCasesInfo.indexOf('TEST:'))
								failedTestCasesInfo = failedTestCasesInfo.substring(0, failedTestCasesInfo.indexOf('Test results:'))
								failedTestCasesInfo = failedTestCasesInfo.split("\\n").join(" ").replaceAll("TEST: ", "")
								if (failedtest.startsWith("jdk_")) {
									if (!jdkFailedTestCaseList.contains(failedTestCasesInfo)) {
										jdkFailedTestCaseList += "${failedTestCasesInfo} "
									}									
								} else if (failedtest.startsWith("jck-runtime") || failedtest.startsWith("jckruntime")) {
									if (!jckRuntimeFailedTestCaseList.contains(failedTestCasesInfo)) {
										jckRuntimeFailedTestCaseList += "${failedTestCasesInfo} "
									}
								} else if (failedtest.startsWith("jck-compiler") || failedtest.startsWith("jckcompiler")) {
									if (!jckCompilerFailedTestCaseList.contains(failedTestCasesInfo)) {
										jckCompilerFailedTestCaseList += "${failedTestCasesInfo} "
									}
								} else if (failedtest.startsWith("jck-devtools") || failedtest.startsWith("jckdevtools")) {
									if (!jckDevtoolsFailedTestCaseList.contains(failedTestCasesInfo)) {
										jckDevtoolsFailedTestCaseList += "${failedTestCasesInfo} "
									}
								} else {
									if (!hotspotFailedTestCaseList.contains(failedTestCasesInfo)) {
										hotspotFailedTestCaseList += "${failedTestCasesInfo} "
									}
								}
							}
						}
					}
				}
			}
		}
		if (failedTestList) {
			String failedTests = failedTestList.substring(0, failedTestList.length() - 1)
			env.FAILED_TESTS= failedTests ?: ""
			env.RERUN_TESTCASES=""
			failedTestList = "testList+TESTLIST=" + failedTests
			String url = env.RERUN_LINK
			def failedTestUrl = url.replace(env.FAILED_TEST_TARGET, "TARGET=$failedTestList")
			echo "Rerun in Grinder with failed test targets: ${failedTestUrl}"
			currentBuild.description += "<br><a href=${failedTestUrl}> Rerun in Grinder with failed test targets</a>"
			def customizedTestCases = [:]
			if (jdkFailedTestCaseList) {
				customizedTestCases['jdk'] = "${jdkFailedTestCaseList}"
			}
			if (hotspotFailedTestCaseList) {
				customizedTestCases['hotspot'] = "${hotspotFailedTestCaseList}"
			}
			if (jckRuntimeFailedTestCaseList) {
				customizedTestCases['jckruntime'] = "${jckRuntimeFailedTestCaseList}"
			}
			if (jckCompilerFailedTestCaseList) {
				customizedTestCases['jckcompiler'] = "${jckCompilerFailedTestCaseList}"
			}
			if (jckDevtoolsFailedTestCaseList) {
				customizedTestCases['jckdevtools'] = "${jckDevtoolsFailedTestCaseList}"
			}

			if (customizedTestCases.size() == 1) {
				def testCases=customizedTestCases.values().first()
				def customTarget=customizedTestCases.keySet().first()
				def testCaseSize=testCases.count(' ')
				// Limitation of Header Fields https://github.com/adoptium/aqa-tests/issues/5241#issuecomment-2161927014
				if (testCaseSize < 80) {
					env.RERUN_CUSTOMTARGET="${customTarget}_custom"
					env.RERUN_TESTCASES="${testCases}"
				}
			}
			customizedTestCases.each { target, testcases ->
				def tempTestCases = testcases.substring(0, testcases.length() - 1)
				tempTestCases = URLEncoder.encode(tempTestCases.toString(), "UTF-8")
				def customURL = url.replace(env.FAILED_TEST_TARGET, "TARGET=${target}_custom")
				customURL = customURL.replace(env.CUSTOM_TARGET_KEY_VALUE, "CUSTOM_TARGET=$tempTestCases")
				echo "Rerun failed ${target} test cases in Grinder with ${target}_custom target: ${customURL}"
				currentBuild.description += "<br><a href=${customURL}> Rerun failed ${target} test cases in Grinder with ${target}_custom target</a>"
			}
		}
	}
}

def generateJob (newJobs, childTest, testJobName) {
	// If GENERATE_JOBS is set to true, force generate the child job. Otherwise, only generate the child job if it does not exist
	if (env.GENERATE_JOBS == 'true') {
		newJobs[childTest] = {
			echo "GENERATE_JOBS is set to true, set test job ${testJobName} params for generating the job"
			createJob(testJobName, PLATFORM)
		}
	} else {
		def jobIsRunnable = false
		try {
			def JobHelper = library(identifier: 'openjdk-jenkins-helper@master').JobHelper
			jobIsRunnable = JobHelper.jobIsRunnable("${testJobName}")
			echo "${testJobName} jobIsRunnable: ${jobIsRunnable}"
		} catch (Exception e) {
			echo "Cannot call jobIsRunnable() from openjdk-jenkins-helper@master. Skipping..."
		}
		if (!jobIsRunnable) {
			newJobs[childTest] = {
				echo "Test job ${testJobName} doesn't exist, set test job ${testJobName} params for generating the job"
				createJob(testJobName, PLATFORM)
			}
		}
	}
}
/* triggerRerunJob() triggers rerun at parent job level. There are two type of rerun builds:
 * - rerun due to failed test(s) - RERUN_ITERATIONS > 0 and list of failed test target(s) (i.e., env.FAILED_TESTS cannot be empty)
 * - rerun due to test job in FAILURE state - RERUN_FAILURE is true and rerunTestJobParams cannot be empty
 * If the JOB_NAME contains _rerun, _testList_ or _iteration_, rerun job will not be triggered at the same level.
*/
def triggerRerunJob (rerunTestJobParams) {
	if (!JOB_NAME.contains("_rerun") && !JOB_NAME.contains("_testList_") && !JOB_NAME.contains("_iteration_")) {
		int rerunIterations = params.RERUN_ITERATIONS ? params.RERUN_ITERATIONS.toInteger() : 0
		if ((rerunIterations > 0 && env.FAILED_TESTS?.trim()) || (params.RERUN_FAILURE && rerunTestJobParams)) {
			stage('Rerun') {
				def rerunTestJobs =[:]
				echo "allocate a node for generating rerun job ..."
				node (env.SETUP_LABEL) {
					if (rerunIterations > 0 && env.FAILED_TESTS?.trim()) {
						def rerunJobName = "${JOB_NAME}_rerun"
						def newJobs = [:]
						def childParams = []
						echo "Generating rerun ${rerunJobName} job for running failed test(s) ..."
						generateJob(newJobs, rerunJobName, rerunJobName)
						parallel newJobs

						// loop through all the params and change the parameters if needed
						params.each { param ->
							// set PARALLEL, NUM_MACHINES and TEST_TIME to default values
							// set TARGET to failed tests and set ITERATIONS to rerunIterations
							if (param.key == "TARGET") {
								if (env.RERUN_TESTCASES) {
									childParams << string(name: param.key, value: env.RERUN_CUSTOMTARGET)
								} else {
									if (env.FAILED_TESTS.contains("_custom")) {
										childParams << string(name: param.key, value: env.FAILED_TESTS)
									} else {
										childParams << string(name: param.key, value: "testList TESTLIST=" + env.FAILED_TESTS)
									}
								}
							} else if (param.key == "CUSTOM_TARGET") {
								if (env.RERUN_TESTCASES) {
									childParams << string(name: param.key, value: env.RERUN_TESTCASES)
								} else {
									childParams << string(name: param.key, value: param.value.toString())
								}
							} else if (param.key == "PARALLEL") {
								childParams << string(name: param.key, value: "None")
							} else if (param.key == "NUM_MACHINES") {
								childParams << string(name: param.key, value: "")
							} else if (param.key == "TEST_TIME") {
								childParams << string(name: param.key, value: "")
							} else if (param.key == "ITERATIONS") {
								childParams << string(name: param.key, value: rerunIterations.toString())
							} else {
								def value = param.value.toString()
								if (value == "true" || value == "false") {
									childParams << booleanParam(name: param.key, value: value.toBoolean())
								} else {
									childParams << string(name: param.key, value: value)
								}
							}
						}
						rerunTestJobs[rerunJobName] = {
							build job: rerunJobName, parameters: childParams, propagate: false
						}
					}
					// generate job to rerun FAILURE test build(s)
					if (params.RERUN_FAILURE && rerunTestJobParams) {
						def newRerunJobs = [:]
						rerunTestJobParams.each {
							name, jobParams ->
								def rerunJobName = "${name}_rerun"
								echo "Generating rerun ${rerunJobName} job for running FAILURE test build(s) ..."
								generateJob(newRerunJobs, rerunJobName, rerunJobName)
								rerunTestJobs[rerunJobName] = {
									build job: rerunJobName, parameters: jobParams, propagate: false
								}
						}
						// generate the new rerun job
						if (newRerunJobs) {
							parallel newRerunJobs
						}
					}
				}
				if (rerunTestJobs) {
					echo "Triggering rerun jobs in parallel ..."
					def childJobs = parallel rerunTestJobs
					archiveChildJobTap(childJobs)
				}
			}
		}
	}
}

def archiveChildJobTap(childJobs) {
	node (env.SETUP_LABEL) {
		def childTestJobParams = [:]
		forceCleanWS()
		try {
			def buildPaths = ""
			childJobs.each {
				cjob ->
					def jobInvocation = cjob.value.getRawBuild()
					def buildId = jobInvocation.getNumber()
					def name = cjob.value.getProjectName()
					def childResult = cjob.value.getCurrentResult()
					echo "${name} #${buildId} completed with status ${childResult}"
					// track childTestJobParams if it is FAILURE job
					if (childResult == "FAILURE") {
						childTestJobParams << parallelTestParams.findAll {it.key == name}
					}

					try {
						timeout(time: 1, unit: 'HOURS') {
							copyArtifacts (projectName: "${name}", selector: specific("${buildId}"), filter: "**/*.tap", target:"${name}/${buildId}")
						}
						step([$class: "TapPublisher", testResults: "${name}/${buildId}/**/*.tap", outputTapToConsole: false, failIfNoResults: true])
						archiveFile("${name}/${buildId}/**/*.tap", true)
						// add failed tests to Grinder link if it is not from the rerun build
						if (!name.contains("_rerun")) {
							buildPaths += "${name}/${buildId}/,"
						}
					} catch (Exception e) {
						echo 'Exception: ' + e.toString()
						echo "Cannot copy *.tap or AQACert.log from ${name} with buildid ${buildId} . Skipping copyArtifacts..."
					}
					if (!currentBuild.resultIsWorseOrEqualTo(childResult)) {
						currentBuild.result = childResult;
					}
			}
			def resultSum = parseResultSumFromTaps()
			checkTestResults(resultSum)

			archiveAQAvitFiles()
			if (buildPaths.length() > 0) {
				addFailedTestsGrinderLink(buildPaths.substring(0, buildPaths.length() - 1))
			}
		} finally {
			forceCleanWS()
		}
		return childTestJobParams
	}
}

def runParallelTests() {
	def rerunTestJobParams = [:]
	if (params.PARALLEL && params.PARALLEL != "None" && (NUM_MACHINES > 1 || params.TEST_TIME)) {
		stage ("Parallel Tests") {
			def childJobs = parallel parallel_tests
			rerunTestJobParams = archiveChildJobTap(childJobs)
		}
	}
	return rerunTestJobParams
}

def parseResultSumFromTaps() {
	def results = [:]
	def tapFiles = findFiles(glob: "**/*.tap")
	for (String tapFile : tapFiles) {
		def tap = readFile(file: "${tapFile}")
		def lines = tap.readLines()
		def found = false
		for (String line : lines) {
			if ((match = line =~ /# RESULTS_SUMMARY: (TOTAL: \d+)\s*(EXECUTED: \d+)\s*(PASSED: \d+)\s*(FAILED: \d+)\s*(DISABLED: \d+)\s*(SKIPPED: \d+)/)) {
				for (int i = 1; i < match.groupCount(); i++) {
					def matchVals = match.group(i).split(": ")
					if (!results[matchVals[0]]) {
						results[matchVals[0]] = 0;
					}
					results[matchVals[0]] += matchVals[1] as int
				}
				found = true
				break
			}
		}
		if (!found) {
			return [:]
		}
	}
	return results
}

def getGitRepoBranch(ownerBranch, defaultOwnerBranch, repo) {
	String[] actualRepoBranch = defaultOwnerBranch.split(":")
	if (ownerBranch) {
		String[] tokens = ownerBranch.split(":")
		if (tokens.size() == 2 ) {
			actualRepoBranch = tokens;
		} else {
			error "[ERROR]: Wrong format of XXX_OWNER_BRANCH value: ${ownerBranch}. The expected format is [owner]:[branch]"
		}
	}

	String owner = actualRepoBranch[0].trim()
	String repoURL = "https://github.com/${owner}/${repo}.git"
	if (env.SPEC.startsWith('zos')) {
		repoURL = repoURL.replace("https://github.com/","git@github.com:")
	}
	actualRepoBranch[0] = repoURL
	actualRepoBranch[1] = actualRepoBranch[1].trim()
	return actualRepoBranch
}

def forceCleanWS() {
	try {
		cleanWs disableDeferredWipeout: true, deleteDirs: true
	} catch (Exception e) {
		echo 'Exception: ' + e.toString()
		//cleanWs has issue to delete workspace that contains non-ASCII filename in TKG output https://issues.jenkins.io/browse/JENKINS-33478
		//cannot delete workspace directly. Otherwise, Jenkins job will abort due to missing workspace
		sh "rm -rf ${env.WORKSPACE}/aqa-tests/TKG"
		// call cleanWs() again
		cleanWs disableDeferredWipeout: true, deleteDirs: true
	}
}

return this
